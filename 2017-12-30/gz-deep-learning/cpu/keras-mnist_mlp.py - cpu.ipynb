{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 1us/step\n",
      "11501568/11490434 [==============================] - 6s 1us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.2450 - acc: 0.9240 - val_loss: 0.1807 - val_acc: 0.9445\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1031 - acc: 0.9693 - val_loss: 0.0851 - val_acc: 0.9765\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0741 - acc: 0.9776 - val_loss: 0.0924 - val_acc: 0.9737\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0611 - acc: 0.9817 - val_loss: 0.0770 - val_acc: 0.9780\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0515 - acc: 0.9848 - val_loss: 0.0904 - val_acc: 0.9772\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0427 - acc: 0.9872 - val_loss: 0.0801 - val_acc: 0.9802\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0398 - acc: 0.9886 - val_loss: 0.0818 - val_acc: 0.9818\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0350 - acc: 0.9903 - val_loss: 0.0817 - val_acc: 0.9832\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0331 - acc: 0.9904 - val_loss: 0.0794 - val_acc: 0.9829\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0296 - acc: 0.9916 - val_loss: 0.0943 - val_acc: 0.9813\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0271 - acc: 0.9924 - val_loss: 0.0937 - val_acc: 0.9831\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0271 - acc: 0.9922 - val_loss: 0.0889 - val_acc: 0.9834\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0232 - acc: 0.9937 - val_loss: 0.0954 - val_acc: 0.9830\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0232 - acc: 0.9938 - val_loss: 0.0961 - val_acc: 0.9837\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0229 - acc: 0.9939 - val_loss: 0.1066 - val_acc: 0.9817\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0205 - acc: 0.9945 - val_loss: 0.1056 - val_acc: 0.9823\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0211 - acc: 0.9947 - val_loss: 0.1087 - val_acc: 0.9824\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0220 - acc: 0.9945 - val_loss: 0.1177 - val_acc: 0.9821\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0199 - acc: 0.9948 - val_loss: 0.1072 - val_acc: 0.9841\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0205 - acc: 0.9951 - val_loss: 0.1218 - val_acc: 0.9817\n",
      "Test loss: 0.121841838039\n",
      "Test accuracy: 0.9817\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with CPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 26s 437us/step - loss: 0.2473 - acc: 0.9232 - val_loss: 0.1081 - val_acc: 0.9675\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 28s 460us/step - loss: 0.1024 - acc: 0.9688 - val_loss: 0.0939 - val_acc: 0.9736\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 30s 499us/step - loss: 0.0759 - acc: 0.9767 - val_loss: 0.0735 - val_acc: 0.9796\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 30s 493us/step - loss: 0.0599 - acc: 0.9819 - val_loss: 0.0776 - val_acc: 0.9789\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.0512 - acc: 0.9841 - val_loss: 0.0773 - val_acc: 0.9792\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.0446 - acc: 0.9873 - val_loss: 0.0744 - val_acc: 0.9819\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0394 - acc: 0.9882 - val_loss: 0.0822 - val_acc: 0.9818\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 32s 528us/step - loss: 0.0351 - acc: 0.9897 - val_loss: 0.0783 - val_acc: 0.9826\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 33s 545us/step - loss: 0.0315 - acc: 0.9909 - val_loss: 0.0901 - val_acc: 0.9818\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 31s 514us/step - loss: 0.0310 - acc: 0.9914 - val_loss: 0.0869 - val_acc: 0.9832\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 30s 506us/step - loss: 0.0258 - acc: 0.9922 - val_loss: 0.0909 - val_acc: 0.9832\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 30s 504us/step - loss: 0.0246 - acc: 0.9928 - val_loss: 0.0871 - val_acc: 0.9838\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 31s 514us/step - loss: 0.0241 - acc: 0.9934 - val_loss: 0.0970 - val_acc: 0.9830\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 31s 514us/step - loss: 0.0235 - acc: 0.9936 - val_loss: 0.1059 - val_acc: 0.9824\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 32s 527us/step - loss: 0.0225 - acc: 0.9941 - val_loss: 0.1049 - val_acc: 0.9826\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 32s 536us/step - loss: 0.0191 - acc: 0.9945 - val_loss: 0.1110 - val_acc: 0.9828\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 31s 522us/step - loss: 0.0199 - acc: 0.9949 - val_loss: 0.1173 - val_acc: 0.9827\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 0.0184 - acc: 0.9950 - val_loss: 0.1015 - val_acc: 0.9848\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 33s 543us/step - loss: 0.0170 - acc: 0.9951 - val_loss: 0.1076 - val_acc: 0.9837\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 44s 727us/step - loss: 0.0167 - acc: 0.9957 - val_loss: 0.1283 - val_acc: 0.9823\n",
      "Test loss: 0.128256206206\n",
      "Test accuracy: 0.9823\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 19s 2us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.9241 - acc: 0.7717 - val_loss: 0.4486 - val_acc: 0.8913\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 31s 524us/step - loss: 0.8964 - acc: 0.8344 - val_loss: 1.3418 - val_acc: 0.8202\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 30s 501us/step - loss: 1.9892 - acc: 0.8203 - val_loss: 1.4119 - val_acc: 0.8863\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 32s 541us/step - loss: 2.8391 - acc: 0.8013 - val_loss: 1.6620 - val_acc: 0.8869\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 30s 507us/step - loss: 3.3716 - acc: 0.7785 - val_loss: 2.3631 - val_acc: 0.8451\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 3.5951 - acc: 0.7684 - val_loss: 4.1890 - val_acc: 0.7328\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 4.0302 - acc: 0.7444 - val_loss: 4.0584 - val_acc: 0.7440\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 4.2534 - acc: 0.7317 - val_loss: 4.7972 - val_acc: 0.7000\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 4.6420 - acc: 0.7088 - val_loss: 4.0971 - val_acc: 0.7437\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 4.4007 - acc: 0.7239 - val_loss: 3.9029 - val_acc: 0.7558\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 35s 584us/step - loss: 5.0190 - acc: 0.6864 - val_loss: 5.8097 - val_acc: 0.6374\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 35s 588us/step - loss: 5.4092 - acc: 0.6627 - val_loss: 4.6837 - val_acc: 0.7078\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 5.6131 - acc: 0.6504 - val_loss: 4.4795 - val_acc: 0.7205\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 31s 515us/step - loss: 5.7551 - acc: 0.6415 - val_loss: 5.1730 - val_acc: 0.6784\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 38s 639us/step - loss: 5.7368 - acc: 0.6428 - val_loss: 3.9650 - val_acc: 0.7527\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 44s 728us/step - loss: 5.6458 - acc: 0.6485 - val_loss: 5.9127 - val_acc: 0.6326\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 47s 783us/step - loss: 6.3282 - acc: 0.6064 - val_loss: 5.5287 - val_acc: 0.6562\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 6.3111 - acc: 0.6074 - val_loss: 5.6053 - val_acc: 0.6514\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 37s 608us/step - loss: 5.7174 - acc: 0.6445 - val_loss: 6.1445 - val_acc: 0.6181\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 36s 593us/step - loss: 6.0851 - acc: 0.6215 - val_loss: 4.5414 - val_acc: 0.7175\n",
      "Test loss: 4.54137091999\n",
      "Test accuracy: 0.7175\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 2.5103 - acc: 0.4352 - val_loss: 1.4593 - val_acc: 0.5707\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 1.0707 - acc: 0.6925 - val_loss: 0.7585 - val_acc: 0.7527\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.9453 - acc: 0.7137 - val_loss: 0.5580 - val_acc: 0.7960\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.7997 - acc: 0.7561 - val_loss: 0.8622 - val_acc: 0.7618\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.8690 - acc: 0.7453 - val_loss: 0.5969 - val_acc: 0.8260\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.8042 - acc: 0.7825 - val_loss: 0.3628 - val_acc: 0.8991\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.5861 - acc: 0.8244 - val_loss: 0.4632 - val_acc: 0.8416\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.8534 - acc: 0.7586 - val_loss: 0.5629 - val_acc: 0.8239\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.6051 - acc: 0.8212 - val_loss: 0.5226 - val_acc: 0.8483\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.5459 - acc: 0.8292 - val_loss: 0.3633 - val_acc: 0.8963\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.6627 - acc: 0.8128 - val_loss: 0.5857 - val_acc: 0.8314\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.6119 - acc: 0.8185 - val_loss: 0.4093 - val_acc: 0.8553\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.4637 - acc: 0.8586 - val_loss: 0.3424 - val_acc: 0.8955\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.6573 - acc: 0.8078 - val_loss: 0.4610 - val_acc: 0.8561\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.4392 - acc: 0.8654 - val_loss: 0.3808 - val_acc: 0.8750\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.4249 - acc: 0.8681 - val_loss: 0.3293 - val_acc: 0.9004\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.5342 - acc: 0.8338 - val_loss: 0.4324 - val_acc: 0.8675\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.4636 - acc: 0.8572 - val_loss: 0.2684 - val_acc: 0.9231\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.4237 - acc: 0.8714 - val_loss: 0.3158 - val_acc: 0.9044\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.4486 - acc: 0.8623 - val_loss: 0.3181 - val_acc: 0.8943\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.3701 - acc: 0.8851 - val_loss: 0.2530 - val_acc: 0.9230\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.4023 - acc: 0.8751 - val_loss: 0.7363 - val_acc: 0.8135\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.5336 - acc: 0.8514 - val_loss: 0.2138 - val_acc: 0.9346\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2991 - acc: 0.9060 - val_loss: 0.2389 - val_acc: 0.9268\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.3476 - acc: 0.8933 - val_loss: 0.3164 - val_acc: 0.8986\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.4517 - acc: 0.8697 - val_loss: 0.2453 - val_acc: 0.9191\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2953 - acc: 0.9073 - val_loss: 0.2793 - val_acc: 0.9045\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.5353 - acc: 0.8554 - val_loss: 0.2127 - val_acc: 0.9318\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2538 - acc: 0.9231 - val_loss: 0.2135 - val_acc: 0.9307\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.3188 - acc: 0.9018 - val_loss: 0.2886 - val_acc: 0.8933\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.4919 - acc: 0.8585 - val_loss: 0.2605 - val_acc: 0.9204\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.2480 - acc: 0.9249 - val_loss: 0.1984 - val_acc: 0.9369\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.2912 - acc: 0.9091 - val_loss: 0.3487 - val_acc: 0.8895\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.4046 - acc: 0.8804 - val_loss: 0.3305 - val_acc: 0.8961\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.2570 - acc: 0.9210 - val_loss: 0.1972 - val_acc: 0.9360\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.3347 - acc: 0.9007 - val_loss: 0.4117 - val_acc: 0.8819\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.2990 - acc: 0.9083 - val_loss: 0.1757 - val_acc: 0.9429\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.2607 - acc: 0.9197 - val_loss: 0.2050 - val_acc: 0.9341\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.3772 - acc: 0.8914 - val_loss: 0.2156 - val_acc: 0.9332\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.2566 - acc: 0.9220 - val_loss: 0.2171 - val_acc: 0.9270\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.2509 - acc: 0.9207 - val_loss: 0.3219 - val_acc: 0.8770\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.3123 - acc: 0.9084 - val_loss: 0.1707 - val_acc: 0.9464\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.2386 - acc: 0.9260 - val_loss: 0.2122 - val_acc: 0.9295\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.3657 - acc: 0.8925 - val_loss: 0.3455 - val_acc: 0.9019\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.2383 - acc: 0.9273 - val_loss: 0.1611 - val_acc: 0.9493\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.2187 - acc: 0.9325 - val_loss: 0.3318 - val_acc: 0.8953\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.3357 - acc: 0.9010 - val_loss: 0.1592 - val_acc: 0.9511\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.1926 - acc: 0.9401 - val_loss: 0.3070 - val_acc: 0.8885\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.2915 - acc: 0.9117 - val_loss: 0.3311 - val_acc: 0.8966\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2351 - acc: 0.9290 - val_loss: 0.1324 - val_acc: 0.9606\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.2305 - acc: 0.9295 - val_loss: 0.2896 - val_acc: 0.9144\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3481 - acc: 0.9056 - val_loss: 0.1624 - val_acc: 0.9491\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.1838 - acc: 0.9433 - val_loss: 0.2447 - val_acc: 0.9250\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.2354 - acc: 0.9286 - val_loss: 0.1824 - val_acc: 0.9402\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.2797 - acc: 0.9130 - val_loss: 0.2308 - val_acc: 0.9328\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1929 - acc: 0.9410 - val_loss: 0.1677 - val_acc: 0.9453\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.2637 - acc: 0.9216 - val_loss: 0.2684 - val_acc: 0.9211\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.2237 - acc: 0.9313 - val_loss: 0.1508 - val_acc: 0.9512\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.2254 - acc: 0.9325 - val_loss: 0.2962 - val_acc: 0.9154\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3014 - acc: 0.9194 - val_loss: 0.1194 - val_acc: 0.9642\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1724 - acc: 0.9473 - val_loss: 0.2052 - val_acc: 0.9317\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.2918 - acc: 0.9160 - val_loss: 0.1330 - val_acc: 0.9575\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1614 - acc: 0.9503 - val_loss: 0.2155 - val_acc: 0.9333\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2569 - acc: 0.9230 - val_loss: 0.1847 - val_acc: 0.9391\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.1863 - acc: 0.9415 - val_loss: 0.1226 - val_acc: 0.9617\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.2438 - acc: 0.9291 - val_loss: 0.2384 - val_acc: 0.9273\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2039 - acc: 0.9401 - val_loss: 0.1125 - val_acc: 0.9663\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2127 - acc: 0.9362 - val_loss: 0.1625 - val_acc: 0.9512\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.2226 - acc: 0.9327 - val_loss: 0.1494 - val_acc: 0.9558\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.1861 - acc: 0.9431 - val_loss: 0.1303 - val_acc: 0.9595\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.2505 - acc: 0.9272 - val_loss: 0.1274 - val_acc: 0.9593\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.1623 - acc: 0.9494 - val_loss: 0.1250 - val_acc: 0.9606\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.3026 - acc: 0.9162 - val_loss: 0.1932 - val_acc: 0.9438\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1656 - acc: 0.9515 - val_loss: 0.1195 - val_acc: 0.9631\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1737 - acc: 0.9474 - val_loss: 0.3701 - val_acc: 0.9052\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.2793 - acc: 0.9232 - val_loss: 0.1179 - val_acc: 0.9633\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1526 - acc: 0.9534 - val_loss: 0.1417 - val_acc: 0.9566\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.2444 - acc: 0.9299 - val_loss: 0.1246 - val_acc: 0.9614\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.1791 - acc: 0.9457 - val_loss: 0.1909 - val_acc: 0.9465\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.2247 - acc: 0.9375 - val_loss: 0.1147 - val_acc: 0.9658\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2118 - acc: 0.9377 - val_loss: 0.5717 - val_acc: 0.8703\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.2337 - acc: 0.9356 - val_loss: 0.1160 - val_acc: 0.9643\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.1809 - acc: 0.9457 - val_loss: 0.1279 - val_acc: 0.9618\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2327 - acc: 0.9347 - val_loss: 0.2323 - val_acc: 0.9369\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2558 - acc: 0.9310 - val_loss: 0.1652 - val_acc: 0.9537\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.1650 - acc: 0.9522 - val_loss: 0.1326 - val_acc: 0.9603\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.2176 - acc: 0.9364 - val_loss: 0.3811 - val_acc: 0.9059\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2754 - acc: 0.9286 - val_loss: 0.1464 - val_acc: 0.9557\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1510 - acc: 0.9548 - val_loss: 0.1271 - val_acc: 0.9615\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.4877 - acc: 0.9011 - val_loss: 0.1894 - val_acc: 0.9539\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.1593 - acc: 0.9569 - val_loss: 0.1184 - val_acc: 0.9654\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2223 - acc: 0.9404 - val_loss: 0.1626 - val_acc: 0.9563\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3622 - acc: 0.9171 - val_loss: 0.2216 - val_acc: 0.9443\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2353 - acc: 0.9415 - val_loss: 0.3588 - val_acc: 0.9161\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2348 - acc: 0.9425 - val_loss: 0.1608 - val_acc: 0.9515\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.4244 - acc: 0.9085 - val_loss: 0.1879 - val_acc: 0.9572\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2910 - acc: 0.9348 - val_loss: 0.2148 - val_acc: 0.9508\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.3106 - acc: 0.9295 - val_loss: 0.6779 - val_acc: 0.8782\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.4616 - acc: 0.9151 - val_loss: 0.1334 - val_acc: 0.9705\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2333 - acc: 0.9460 - val_loss: 0.3844 - val_acc: 0.9255\n",
      "Test loss: 0.384407030706\n",
      "Test accuracy: 0.9255\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Theano tends to smaller batch size; while Tensorflow larger:\n",
    "#batch_size = 128\n",
    "#batch_size = 30000 # too large\n",
    "batch_size = 6000\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 1.1983 - acc: 0.6819 - val_loss: 0.7099 - val_acc: 0.7895\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.7050 - acc: 0.7976 - val_loss: 0.5626 - val_acc: 0.8335\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.5574 - acc: 0.8337 - val_loss: 0.4971 - val_acc: 0.8464\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.4799 - acc: 0.8571 - val_loss: 0.2978 - val_acc: 0.9032\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.4297 - acc: 0.8726 - val_loss: 0.5173 - val_acc: 0.8548\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.3927 - acc: 0.8827 - val_loss: 0.2866 - val_acc: 0.9076\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.3662 - acc: 0.8922 - val_loss: 0.3031 - val_acc: 0.9116\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.3339 - acc: 0.9012 - val_loss: 0.1972 - val_acc: 0.9396\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.3261 - acc: 0.9033 - val_loss: 0.3722 - val_acc: 0.8913\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.3114 - acc: 0.9092 - val_loss: 0.2434 - val_acc: 0.9182\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.3167 - acc: 0.9104 - val_loss: 0.2058 - val_acc: 0.9372\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.2876 - acc: 0.9170 - val_loss: 0.2604 - val_acc: 0.9205\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.2918 - acc: 0.9162 - val_loss: 0.2214 - val_acc: 0.9358\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.2812 - acc: 0.9202 - val_loss: 0.2403 - val_acc: 0.9309\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.3353 - acc: 0.9165 - val_loss: 0.2630 - val_acc: 0.9282\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.3678 - acc: 0.9110 - val_loss: 0.1897 - val_acc: 0.9464\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.4406 - acc: 0.9066 - val_loss: 0.5188 - val_acc: 0.8982\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.5395 - acc: 0.9049 - val_loss: 0.7136 - val_acc: 0.8882\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.7014 - acc: 0.8967 - val_loss: 0.3176 - val_acc: 0.9503\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.8637 - acc: 0.8931 - val_loss: 0.4935 - val_acc: 0.9407\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 1.0482 - acc: 0.8870 - val_loss: 1.3491 - val_acc: 0.8798\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 1.2646 - acc: 0.8806 - val_loss: 1.0923 - val_acc: 0.8966\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 1.4156 - acc: 0.8791 - val_loss: 1.0307 - val_acc: 0.9094\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 1.4507 - acc: 0.8813 - val_loss: 0.8521 - val_acc: 0.9296\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 1.5685 - acc: 0.8767 - val_loss: 1.1308 - val_acc: 0.9137\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 1.6071 - acc: 0.8791 - val_loss: 1.4745 - val_acc: 0.8907\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 1.6431 - acc: 0.8785 - val_loss: 1.2959 - val_acc: 0.9046\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 1.7365 - acc: 0.8758 - val_loss: 1.2037 - val_acc: 0.9134\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 1.7365 - acc: 0.8768 - val_loss: 1.5784 - val_acc: 0.8889\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 1.7479 - acc: 0.8785 - val_loss: 1.0516 - val_acc: 0.9268\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 1.8570 - acc: 0.8728 - val_loss: 1.3460 - val_acc: 0.9073\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 1.8154 - acc: 0.8770 - val_loss: 1.2641 - val_acc: 0.9127\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 1.8358 - acc: 0.8767 - val_loss: 1.3579 - val_acc: 0.9094\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 1.8872 - acc: 0.8743 - val_loss: 1.9626 - val_acc: 0.8703\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 1.8919 - acc: 0.8751 - val_loss: 2.3795 - val_acc: 0.8440\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 1.9120 - acc: 0.8742 - val_loss: 1.2970 - val_acc: 0.9150\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 1.8307 - acc: 0.8799 - val_loss: 1.9436 - val_acc: 0.8739\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 1.8584 - acc: 0.8791 - val_loss: 1.6671 - val_acc: 0.8913\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 1.9972 - acc: 0.8702 - val_loss: 2.2106 - val_acc: 0.8561\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 1.9345 - acc: 0.8746 - val_loss: 1.7419 - val_acc: 0.8876\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 1.9496 - acc: 0.8741 - val_loss: 2.6128 - val_acc: 0.8313\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 20s 334us/step - loss: 1.9705 - acc: 0.8730 - val_loss: 1.1595 - val_acc: 0.9244\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 22s 361us/step - loss: 1.9327 - acc: 0.8756 - val_loss: 1.7940 - val_acc: 0.8849\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 1.9549 - acc: 0.8747 - val_loss: 1.5323 - val_acc: 0.9019\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 2.0146 - acc: 0.8711 - val_loss: 1.6620 - val_acc: 0.8937\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 2.0713 - acc: 0.8679 - val_loss: 1.7558 - val_acc: 0.8880\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 1.9827 - acc: 0.8738 - val_loss: 1.5505 - val_acc: 0.9019\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 2.1412 - acc: 0.8641 - val_loss: 2.6389 - val_acc: 0.8325\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 2.0914 - acc: 0.8671 - val_loss: 1.4916 - val_acc: 0.9052\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 2.0336 - acc: 0.8708 - val_loss: 1.3915 - val_acc: 0.9121\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.0807 - acc: 0.8676 - val_loss: 1.5742 - val_acc: 0.8999\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 13s 208us/step - loss: 1.9588 - acc: 0.8759 - val_loss: 2.1175 - val_acc: 0.8661\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 2.0648 - acc: 0.8694 - val_loss: 1.4165 - val_acc: 0.9101\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 2.1232 - acc: 0.8659 - val_loss: 2.0052 - val_acc: 0.8735\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 2.0777 - acc: 0.8688 - val_loss: 1.8510 - val_acc: 0.8835\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.3462 - acc: 0.8523 - val_loss: 1.8061 - val_acc: 0.8864\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.2410 - acc: 0.8587 - val_loss: 1.6277 - val_acc: 0.8973\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 2.2313 - acc: 0.8593 - val_loss: 1.7725 - val_acc: 0.8885\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 2.1204 - acc: 0.8664 - val_loss: 2.8374 - val_acc: 0.8225\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 2.2976 - acc: 0.8555 - val_loss: 2.5855 - val_acc: 0.8374\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 2.2642 - acc: 0.8575 - val_loss: 1.5622 - val_acc: 0.9017\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 2.2595 - acc: 0.8578 - val_loss: 1.3797 - val_acc: 0.9126\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 2.2389 - acc: 0.8593 - val_loss: 2.0292 - val_acc: 0.8723\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 2.3240 - acc: 0.8541 - val_loss: 2.4967 - val_acc: 0.8439\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 2.5400 - acc: 0.8408 - val_loss: 2.0424 - val_acc: 0.8718\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 2.3002 - acc: 0.8557 - val_loss: 2.1501 - val_acc: 0.8648\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 2.3142 - acc: 0.8549 - val_loss: 2.0986 - val_acc: 0.8678\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.3841 - acc: 0.8508 - val_loss: 1.5505 - val_acc: 0.9024\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 2.2201 - acc: 0.8607 - val_loss: 2.1150 - val_acc: 0.8672\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.4487 - acc: 0.8467 - val_loss: 3.5577 - val_acc: 0.7771\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 2.4842 - acc: 0.8446 - val_loss: 2.5075 - val_acc: 0.8428\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.3675 - acc: 0.8517 - val_loss: 1.2957 - val_acc: 0.9190\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.4414 - acc: 0.8473 - val_loss: 1.7956 - val_acc: 0.8876\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.2903 - acc: 0.8566 - val_loss: 3.0321 - val_acc: 0.8110\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 2.4545 - acc: 0.8464 - val_loss: 2.1510 - val_acc: 0.8655\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 2.3778 - acc: 0.8512 - val_loss: 1.7122 - val_acc: 0.8931\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.4927 - acc: 0.8442 - val_loss: 1.7575 - val_acc: 0.8899\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 2.3570 - acc: 0.8526 - val_loss: 3.2388 - val_acc: 0.7984\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 2.3317 - acc: 0.8543 - val_loss: 1.9705 - val_acc: 0.8770\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.5572 - acc: 0.8402 - val_loss: 2.1015 - val_acc: 0.8683\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 2.5155 - acc: 0.8427 - val_loss: 1.4622 - val_acc: 0.9086\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 2.3565 - acc: 0.8528 - val_loss: 2.5910 - val_acc: 0.8383\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 2.5259 - acc: 0.8422 - val_loss: 1.2941 - val_acc: 0.9189\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 2.5268 - acc: 0.8422 - val_loss: 1.6586 - val_acc: 0.8964\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.3378 - acc: 0.8540 - val_loss: 1.6145 - val_acc: 0.8991\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.4844 - acc: 0.8449 - val_loss: 3.4026 - val_acc: 0.7876\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 2.3859 - acc: 0.8511 - val_loss: 2.2780 - val_acc: 0.8580\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 2.6985 - acc: 0.8317 - val_loss: 1.5609 - val_acc: 0.9023\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 13s 208us/step - loss: 2.4164 - acc: 0.8491 - val_loss: 3.2581 - val_acc: 0.7970\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 2.5671 - acc: 0.8397 - val_loss: 3.4832 - val_acc: 0.7829\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 2.4330 - acc: 0.8481 - val_loss: 1.7449 - val_acc: 0.8910\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.4962 - acc: 0.8442 - val_loss: 2.1070 - val_acc: 0.8684\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 2.7045 - acc: 0.8313 - val_loss: 2.9763 - val_acc: 0.8140\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 2.4413 - acc: 0.8477 - val_loss: 1.3688 - val_acc: 0.9145\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 2.5852 - acc: 0.8386 - val_loss: 1.4483 - val_acc: 0.9097\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.7827 - acc: 0.8266 - val_loss: 2.0646 - val_acc: 0.8712\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.5853 - acc: 0.8388 - val_loss: 2.0162 - val_acc: 0.8739\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.3367 - acc: 0.8542 - val_loss: 1.7849 - val_acc: 0.8891\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.5639 - acc: 0.8403 - val_loss: 2.6092 - val_acc: 0.8369\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 2.4563 - acc: 0.8469 - val_loss: 2.3488 - val_acc: 0.8533\n",
      "Test loss: 2.34884084501\n",
      "Test accuracy: 0.8533\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Theano tends to smaller batch size; while Tensorflow larger:\n",
    "#batch_size = 128\n",
    "batch_size = 1024\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
