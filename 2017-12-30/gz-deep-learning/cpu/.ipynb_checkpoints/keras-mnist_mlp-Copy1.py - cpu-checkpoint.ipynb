{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with GPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 1us/step\n",
      "11501568/11490434 [==============================] - 6s 1us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 7s 118us/step - loss: 0.2450 - acc: 0.9240 - val_loss: 0.1807 - val_acc: 0.9445\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 8s 136us/step - loss: 0.1031 - acc: 0.9693 - val_loss: 0.0851 - val_acc: 0.9765\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 9s 145us/step - loss: 0.0741 - acc: 0.9776 - val_loss: 0.0924 - val_acc: 0.9737\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0611 - acc: 0.9817 - val_loss: 0.0770 - val_acc: 0.9780\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 9s 146us/step - loss: 0.0515 - acc: 0.9848 - val_loss: 0.0904 - val_acc: 0.9772\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0427 - acc: 0.9872 - val_loss: 0.0801 - val_acc: 0.9802\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0398 - acc: 0.9886 - val_loss: 0.0818 - val_acc: 0.9818\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 9s 147us/step - loss: 0.0350 - acc: 0.9903 - val_loss: 0.0817 - val_acc: 0.9832\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 9s 148us/step - loss: 0.0331 - acc: 0.9904 - val_loss: 0.0794 - val_acc: 0.9829\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.0296 - acc: 0.9916 - val_loss: 0.0943 - val_acc: 0.9813\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0271 - acc: 0.9924 - val_loss: 0.0937 - val_acc: 0.9831\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 9s 149us/step - loss: 0.0271 - acc: 0.9922 - val_loss: 0.0889 - val_acc: 0.9834\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.0232 - acc: 0.9937 - val_loss: 0.0954 - val_acc: 0.9830\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0232 - acc: 0.9938 - val_loss: 0.0961 - val_acc: 0.9837\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 7s 121us/step - loss: 0.0229 - acc: 0.9939 - val_loss: 0.1066 - val_acc: 0.9817\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 8s 140us/step - loss: 0.0205 - acc: 0.9945 - val_loss: 0.1056 - val_acc: 0.9823\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.0211 - acc: 0.9947 - val_loss: 0.1087 - val_acc: 0.9824\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.0220 - acc: 0.9945 - val_loss: 0.1177 - val_acc: 0.9821\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0199 - acc: 0.9948 - val_loss: 0.1072 - val_acc: 0.9841\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.0205 - acc: 0.9951 - val_loss: 0.1218 - val_acc: 0.9817\n",
      "Test loss: 0.121841838039\n",
      "Test accuracy: 0.9817\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run with CPU:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 15s 1us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 34s 563us/step - loss: 0.2453 - acc: 0.9248 - val_loss: 0.1003 - val_acc: 0.9682\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 34s 561us/step - loss: 0.1030 - acc: 0.9688 - val_loss: 0.0825 - val_acc: 0.9743\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 34s 575us/step - loss: 0.0740 - acc: 0.9774 - val_loss: 0.0803 - val_acc: 0.9780\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 35s 585us/step - loss: 0.0584 - acc: 0.9822 - val_loss: 0.0797 - val_acc: 0.9788\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 33s 547us/step - loss: 0.0513 - acc: 0.9843 - val_loss: 0.0769 - val_acc: 0.9804\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 29s 489us/step - loss: 0.0436 - acc: 0.9873 - val_loss: 0.0689 - val_acc: 0.9833\n",
      "Epoch 7/20\n",
      "11776/60000 [====>.........................] - ETA: 25s - loss: 0.0390 - acc: 0.9890"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-56fb4865d357>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-88d96843a926>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 19s 2us/step\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 32s 539us/step - loss: 0.9241 - acc: 0.7717 - val_loss: 0.4486 - val_acc: 0.8913\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 31s 524us/step - loss: 0.8964 - acc: 0.8344 - val_loss: 1.3418 - val_acc: 0.8202\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 30s 501us/step - loss: 1.9892 - acc: 0.8203 - val_loss: 1.4119 - val_acc: 0.8863\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 32s 541us/step - loss: 2.8391 - acc: 0.8013 - val_loss: 1.6620 - val_acc: 0.8869\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 30s 507us/step - loss: 3.3716 - acc: 0.7785 - val_loss: 2.3631 - val_acc: 0.8451\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 3.5951 - acc: 0.7684 - val_loss: 4.1890 - val_acc: 0.7328\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 4.0302 - acc: 0.7444 - val_loss: 4.0584 - val_acc: 0.7440\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 4.2534 - acc: 0.7317 - val_loss: 4.7972 - val_acc: 0.7000\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 4.6420 - acc: 0.7088 - val_loss: 4.0971 - val_acc: 0.7437\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 4.4007 - acc: 0.7239 - val_loss: 3.9029 - val_acc: 0.7558\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 35s 584us/step - loss: 5.0190 - acc: 0.6864 - val_loss: 5.8097 - val_acc: 0.6374\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 35s 588us/step - loss: 5.4092 - acc: 0.6627 - val_loss: 4.6837 - val_acc: 0.7078\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 34s 559us/step - loss: 5.6131 - acc: 0.6504 - val_loss: 4.4795 - val_acc: 0.7205\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 31s 515us/step - loss: 5.7551 - acc: 0.6415 - val_loss: 5.1730 - val_acc: 0.6784\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 38s 639us/step - loss: 5.7368 - acc: 0.6428 - val_loss: 3.9650 - val_acc: 0.7527\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 44s 728us/step - loss: 5.6458 - acc: 0.6485 - val_loss: 5.9127 - val_acc: 0.6326\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 47s 783us/step - loss: 6.3282 - acc: 0.6064 - val_loss: 5.5287 - val_acc: 0.6562\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 28s 466us/step - loss: 6.3111 - acc: 0.6074 - val_loss: 5.6053 - val_acc: 0.6514\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 37s 608us/step - loss: 5.7174 - acc: 0.6445 - val_loss: 6.1445 - val_acc: 0.6181\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 36s 593us/step - loss: 6.0851 - acc: 0.6215 - val_loss: 4.5414 - val_acc: 0.7175\n",
      "Test loss: 4.54137091999\n",
      "Test accuracy: 0.7175\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/800\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 2.0390 - acc: 0.3031 - val_loss: 2.0833 - val_acc: 0.4786\n",
      "Epoch 2/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 2.3411 - acc: 0.4713 - val_loss: 3.4254 - val_acc: 0.3068\n",
      "Epoch 3/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 3.3690 - acc: 0.3238 - val_loss: 3.1643 - val_acc: 0.4941\n",
      "Epoch 4/800\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 2.9980 - acc: 0.5042 - val_loss: 1.7439 - val_acc: 0.4649\n",
      "Epoch 5/800\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 1.7786 - acc: 0.5714 - val_loss: 1.0976 - val_acc: 0.7482\n",
      "Epoch 6/800\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 1.0915 - acc: 0.6826 - val_loss: 1.0503 - val_acc: 0.7330\n",
      "Epoch 7/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 1.0445 - acc: 0.7042 - val_loss: 0.6889 - val_acc: 0.7730\n",
      "Epoch 8/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.8979 - acc: 0.7072 - val_loss: 1.0967 - val_acc: 0.7236\n",
      "Epoch 9/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 1.1052 - acc: 0.6901 - val_loss: 0.9742 - val_acc: 0.7297\n",
      "Epoch 10/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.9264 - acc: 0.7269 - val_loss: 0.6347 - val_acc: 0.7969\n",
      "Epoch 11/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.7495 - acc: 0.7539 - val_loss: 0.7425 - val_acc: 0.7827\n",
      "Epoch 12/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.8297 - acc: 0.7412 - val_loss: 0.9049 - val_acc: 0.7175\n",
      "Epoch 13/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 1.0219 - acc: 0.7054 - val_loss: 0.7168 - val_acc: 0.7959\n",
      "Epoch 14/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.8053 - acc: 0.7633 - val_loss: 0.9369 - val_acc: 0.7031\n",
      "Epoch 15/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 1.2280 - acc: 0.6687 - val_loss: 1.1849 - val_acc: 0.7418\n",
      "Epoch 16/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 1.1837 - acc: 0.7017 - val_loss: 1.0274 - val_acc: 0.7169\n",
      "Epoch 17/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 1.1322 - acc: 0.6906 - val_loss: 0.7740 - val_acc: 0.8123\n",
      "Epoch 18/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.7157 - acc: 0.8026 - val_loss: 0.4754 - val_acc: 0.8595\n",
      "Epoch 19/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5882 - acc: 0.8170 - val_loss: 0.5768 - val_acc: 0.8395\n",
      "Epoch 20/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.6431 - acc: 0.8059 - val_loss: 0.6577 - val_acc: 0.8046\n",
      "Epoch 21/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.8085 - acc: 0.7761 - val_loss: 0.6369 - val_acc: 0.8047\n",
      "Epoch 22/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.7641 - acc: 0.7731 - val_loss: 0.6449 - val_acc: 0.8022\n",
      "Epoch 23/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.7929 - acc: 0.7568 - val_loss: 1.0495 - val_acc: 0.7665\n",
      "Epoch 24/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 1.1611 - acc: 0.7091 - val_loss: 0.8121 - val_acc: 0.7815\n",
      "Epoch 25/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.8098 - acc: 0.7778 - val_loss: 0.4385 - val_acc: 0.8629\n",
      "Epoch 26/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.5542 - acc: 0.8244 - val_loss: 0.5385 - val_acc: 0.8327\n",
      "Epoch 27/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6554 - acc: 0.7982 - val_loss: 0.7151 - val_acc: 0.8067\n",
      "Epoch 28/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.7498 - acc: 0.7808 - val_loss: 0.8270 - val_acc: 0.7465\n",
      "Epoch 29/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.9637 - acc: 0.7404 - val_loss: 0.7232 - val_acc: 0.7781\n",
      "Epoch 30/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.8333 - acc: 0.7563 - val_loss: 0.5664 - val_acc: 0.8316\n",
      "Epoch 31/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6647 - acc: 0.8003 - val_loss: 0.5175 - val_acc: 0.8467\n",
      "Epoch 32/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.6803 - acc: 0.7957 - val_loss: 0.8870 - val_acc: 0.7511\n",
      "Epoch 33/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.9677 - acc: 0.7385 - val_loss: 1.0418 - val_acc: 0.7792\n",
      "Epoch 34/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.9790 - acc: 0.7731 - val_loss: 0.5848 - val_acc: 0.8303\n",
      "Epoch 35/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.7155 - acc: 0.7996 - val_loss: 0.4085 - val_acc: 0.8830\n",
      "Epoch 36/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.4821 - acc: 0.8553 - val_loss: 0.3471 - val_acc: 0.9012\n",
      "Epoch 37/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.4288 - acc: 0.8717 - val_loss: 0.3402 - val_acc: 0.9019\n",
      "Epoch 38/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.4336 - acc: 0.8689 - val_loss: 0.4379 - val_acc: 0.8569\n",
      "Epoch 39/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6537 - acc: 0.8011 - val_loss: 0.8212 - val_acc: 0.8127\n",
      "Epoch 40/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.7301 - acc: 0.8099 - val_loss: 0.4884 - val_acc: 0.8508\n",
      "Epoch 41/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6320 - acc: 0.8038 - val_loss: 0.6239 - val_acc: 0.8049\n",
      "Epoch 42/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.7884 - acc: 0.7679 - val_loss: 0.5496 - val_acc: 0.8320\n",
      "Epoch 43/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.7633 - acc: 0.7777 - val_loss: 0.7777 - val_acc: 0.7700\n",
      "Epoch 44/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.8518 - acc: 0.7631 - val_loss: 0.6766 - val_acc: 0.8151\n",
      "Epoch 45/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7821 - acc: 0.7870 - val_loss: 0.6105 - val_acc: 0.8334\n",
      "Epoch 46/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.6844 - acc: 0.8119 - val_loss: 0.4007 - val_acc: 0.8789\n",
      "Epoch 47/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.5368 - acc: 0.8422 - val_loss: 0.3609 - val_acc: 0.8924\n",
      "Epoch 48/800\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.4645 - acc: 0.8590 - val_loss: 0.3601 - val_acc: 0.8960\n",
      "Epoch 49/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.4458 - acc: 0.8642 - val_loss: 0.4687 - val_acc: 0.8531\n",
      "Epoch 50/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.5421 - acc: 0.8313 - val_loss: 0.5797 - val_acc: 0.8222\n",
      "Epoch 51/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.5798 - acc: 0.8246 - val_loss: 0.5187 - val_acc: 0.8483\n",
      "Epoch 52/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5901 - acc: 0.8255 - val_loss: 0.5559 - val_acc: 0.8266\n",
      "Epoch 53/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.6222 - acc: 0.8101 - val_loss: 0.6765 - val_acc: 0.7923\n",
      "Epoch 54/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6785 - acc: 0.7998 - val_loss: 0.4689 - val_acc: 0.8573\n",
      "Epoch 55/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5466 - acc: 0.8351 - val_loss: 0.4511 - val_acc: 0.8685\n",
      "Epoch 56/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5440 - acc: 0.8383 - val_loss: 0.4939 - val_acc: 0.8532\n",
      "Epoch 57/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.5463 - acc: 0.8347 - val_loss: 0.4240 - val_acc: 0.8735\n",
      "Epoch 58/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4651 - acc: 0.8566 - val_loss: 0.4254 - val_acc: 0.8723\n",
      "Epoch 59/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5256 - acc: 0.8339 - val_loss: 0.6171 - val_acc: 0.8339\n",
      "Epoch 60/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5663 - acc: 0.8355 - val_loss: 0.3501 - val_acc: 0.8914\n",
      "Epoch 61/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4127 - acc: 0.8689 - val_loss: 0.4271 - val_acc: 0.8590\n",
      "Epoch 62/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.4853 - acc: 0.8432 - val_loss: 0.5066 - val_acc: 0.8363\n",
      "Epoch 63/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5668 - acc: 0.8235 - val_loss: 0.4555 - val_acc: 0.8581\n",
      "Epoch 64/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.5210 - acc: 0.8409 - val_loss: 0.3986 - val_acc: 0.8824\n",
      "Epoch 65/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.5119 - acc: 0.8511 - val_loss: 0.3871 - val_acc: 0.8809\n",
      "Epoch 66/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.4652 - acc: 0.8613 - val_loss: 0.3138 - val_acc: 0.9039\n",
      "Epoch 67/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4270 - acc: 0.8669 - val_loss: 0.4007 - val_acc: 0.8762\n",
      "Epoch 68/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.5523 - acc: 0.8365 - val_loss: 0.4061 - val_acc: 0.8724\n",
      "Epoch 69/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5283 - acc: 0.8281 - val_loss: 0.4882 - val_acc: 0.8427\n",
      "Epoch 70/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.4806 - acc: 0.8491 - val_loss: 0.3001 - val_acc: 0.9120\n",
      "Epoch 71/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3680 - acc: 0.8896 - val_loss: 0.3818 - val_acc: 0.8861\n",
      "Epoch 72/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6138 - acc: 0.8271 - val_loss: 1.0264 - val_acc: 0.7295\n",
      "Epoch 73/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 1.0604 - acc: 0.7316 - val_loss: 0.8496 - val_acc: 0.7977\n",
      "Epoch 74/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.7242 - acc: 0.8083 - val_loss: 0.5221 - val_acc: 0.8417\n",
      "Epoch 75/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.5543 - acc: 0.8345 - val_loss: 0.3684 - val_acc: 0.8855\n",
      "Epoch 76/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.3863 - acc: 0.8823 - val_loss: 0.2577 - val_acc: 0.9234\n",
      "Epoch 77/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3266 - acc: 0.9020 - val_loss: 0.2594 - val_acc: 0.9221\n",
      "Epoch 78/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.3341 - acc: 0.8967 - val_loss: 0.2849 - val_acc: 0.9129\n",
      "Epoch 79/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3767 - acc: 0.8798 - val_loss: 0.3116 - val_acc: 0.9018\n",
      "Epoch 80/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3966 - acc: 0.8725 - val_loss: 0.3298 - val_acc: 0.8948\n",
      "Epoch 81/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.4087 - acc: 0.8700 - val_loss: 0.4463 - val_acc: 0.8383\n",
      "Epoch 82/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.5449 - acc: 0.8257 - val_loss: 0.3805 - val_acc: 0.8724\n",
      "Epoch 83/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.4699 - acc: 0.8557 - val_loss: 0.4397 - val_acc: 0.8469\n",
      "Epoch 84/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4974 - acc: 0.8407 - val_loss: 0.2887 - val_acc: 0.9128\n",
      "Epoch 85/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3533 - acc: 0.8918 - val_loss: 0.2912 - val_acc: 0.9147\n",
      "Epoch 86/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3842 - acc: 0.8804 - val_loss: 0.3415 - val_acc: 0.8944\n",
      "Epoch 87/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.3979 - acc: 0.8741 - val_loss: 0.3000 - val_acc: 0.9073\n",
      "Epoch 88/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3809 - acc: 0.8787 - val_loss: 0.4278 - val_acc: 0.8624\n",
      "Epoch 89/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.5386 - acc: 0.8291 - val_loss: 0.8297 - val_acc: 0.7551\n",
      "Epoch 90/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.8819 - acc: 0.7613 - val_loss: 0.5716 - val_acc: 0.8286\n",
      "Epoch 91/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6754 - acc: 0.8103 - val_loss: 0.3789 - val_acc: 0.8902\n",
      "Epoch 92/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4406 - acc: 0.8673 - val_loss: 0.2860 - val_acc: 0.9140\n",
      "Epoch 93/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3661 - acc: 0.8875 - val_loss: 0.2777 - val_acc: 0.9147\n",
      "Epoch 94/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3487 - acc: 0.8918 - val_loss: 0.2511 - val_acc: 0.9226\n",
      "Epoch 95/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.3178 - acc: 0.9031 - val_loss: 0.2394 - val_acc: 0.9268\n",
      "Epoch 96/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3100 - acc: 0.9053 - val_loss: 0.2417 - val_acc: 0.9242\n",
      "Epoch 97/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3182 - acc: 0.9019 - val_loss: 0.2453 - val_acc: 0.9235\n",
      "Epoch 98/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3223 - acc: 0.9002 - val_loss: 0.2424 - val_acc: 0.9258\n",
      "Epoch 99/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.3240 - acc: 0.9006 - val_loss: 0.2626 - val_acc: 0.9188\n",
      "Epoch 100/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.3596 - acc: 0.8886 - val_loss: 0.3512 - val_acc: 0.8949\n",
      "Epoch 101/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.5037 - acc: 0.8491 - val_loss: 0.6579 - val_acc: 0.8270\n",
      "Epoch 102/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.8260 - acc: 0.7814 - val_loss: 0.7851 - val_acc: 0.8377\n",
      "Epoch 103/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6762 - acc: 0.8345 - val_loss: 0.5079 - val_acc: 0.8392\n",
      "Epoch 104/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5110 - acc: 0.8427 - val_loss: 0.3812 - val_acc: 0.8778\n",
      "Epoch 105/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4013 - acc: 0.8720 - val_loss: 0.2879 - val_acc: 0.9047\n",
      "Epoch 106/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.3266 - acc: 0.8978 - val_loss: 0.2627 - val_acc: 0.9170\n",
      "Epoch 107/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.3046 - acc: 0.9058 - val_loss: 0.2503 - val_acc: 0.9238\n",
      "Epoch 108/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2963 - acc: 0.9083 - val_loss: 0.2317 - val_acc: 0.9271\n",
      "Epoch 109/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.2756 - acc: 0.9164 - val_loss: 0.2148 - val_acc: 0.9317\n",
      "Epoch 110/800\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.2632 - acc: 0.9201 - val_loss: 0.2149 - val_acc: 0.9323\n",
      "Epoch 111/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.2641 - acc: 0.9192 - val_loss: 0.2353 - val_acc: 0.9251\n",
      "Epoch 112/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.3056 - acc: 0.9026 - val_loss: 0.3004 - val_acc: 0.9024\n",
      "Epoch 113/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.3531 - acc: 0.8863 - val_loss: 0.3053 - val_acc: 0.9002\n",
      "Epoch 114/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.4820 - acc: 0.8592 - val_loss: 0.4381 - val_acc: 0.8544\n",
      "Epoch 115/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.6827 - acc: 0.8037 - val_loss: 0.3901 - val_acc: 0.8718\n",
      "Epoch 116/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5141 - acc: 0.8407 - val_loss: 0.4256 - val_acc: 0.8611\n",
      "Epoch 117/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3994 - acc: 0.8764 - val_loss: 0.2756 - val_acc: 0.9151\n",
      "Epoch 118/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4021 - acc: 0.8714 - val_loss: 0.3281 - val_acc: 0.8963\n",
      "Epoch 119/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.3779 - acc: 0.8841 - val_loss: 0.2351 - val_acc: 0.9299\n",
      "Epoch 120/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2894 - acc: 0.9135 - val_loss: 0.2565 - val_acc: 0.9229\n",
      "Epoch 121/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2969 - acc: 0.9092 - val_loss: 0.2290 - val_acc: 0.9296\n",
      "Epoch 122/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2696 - acc: 0.9176 - val_loss: 0.2062 - val_acc: 0.9376\n",
      "Epoch 123/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2583 - acc: 0.9202 - val_loss: 0.2434 - val_acc: 0.9212\n",
      "Epoch 124/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.3460 - acc: 0.8947 - val_loss: 0.3266 - val_acc: 0.8866\n",
      "Epoch 125/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3836 - acc: 0.8778 - val_loss: 0.2700 - val_acc: 0.9179\n",
      "Epoch 126/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.3300 - acc: 0.8994 - val_loss: 0.3990 - val_acc: 0.8752\n",
      "Epoch 127/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.5037 - acc: 0.8537 - val_loss: 0.5294 - val_acc: 0.8376\n",
      "Epoch 128/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5625 - acc: 0.8339 - val_loss: 0.3884 - val_acc: 0.8824\n",
      "Epoch 129/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4311 - acc: 0.8690 - val_loss: 0.3762 - val_acc: 0.8782\n",
      "Epoch 130/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3872 - acc: 0.8806 - val_loss: 0.2674 - val_acc: 0.9132\n",
      "Epoch 131/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3081 - acc: 0.9042 - val_loss: 0.2442 - val_acc: 0.9207\n",
      "Epoch 132/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.2979 - acc: 0.9040 - val_loss: 0.2604 - val_acc: 0.9164\n",
      "Epoch 133/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3017 - acc: 0.9051 - val_loss: 0.2497 - val_acc: 0.9188\n",
      "Epoch 134/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2810 - acc: 0.9113 - val_loss: 0.2098 - val_acc: 0.9331\n",
      "Epoch 135/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2593 - acc: 0.9194 - val_loss: 0.2195 - val_acc: 0.9311\n",
      "Epoch 136/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2824 - acc: 0.9107 - val_loss: 0.2316 - val_acc: 0.9267\n",
      "Epoch 137/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.2998 - acc: 0.9070 - val_loss: 0.2277 - val_acc: 0.9301\n",
      "Epoch 138/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2940 - acc: 0.9108 - val_loss: 0.2503 - val_acc: 0.9213\n",
      "Epoch 139/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3705 - acc: 0.8880 - val_loss: 0.3876 - val_acc: 0.8790\n",
      "Epoch 140/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4583 - acc: 0.8632 - val_loss: 0.3499 - val_acc: 0.8896\n",
      "Epoch 141/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4303 - acc: 0.8744 - val_loss: 0.4618 - val_acc: 0.8523\n",
      "Epoch 142/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.5072 - acc: 0.8468 - val_loss: 0.4312 - val_acc: 0.8625\n",
      "Epoch 143/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4504 - acc: 0.8632 - val_loss: 0.4466 - val_acc: 0.8706\n",
      "Epoch 144/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.3691 - acc: 0.8923 - val_loss: 0.2017 - val_acc: 0.9374\n",
      "Epoch 145/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2338 - acc: 0.9290 - val_loss: 0.1817 - val_acc: 0.9429\n",
      "Epoch 146/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2258 - acc: 0.9310 - val_loss: 0.1856 - val_acc: 0.9392\n",
      "Epoch 147/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2304 - acc: 0.9286 - val_loss: 0.1999 - val_acc: 0.9325\n",
      "Epoch 148/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2526 - acc: 0.9199 - val_loss: 0.2525 - val_acc: 0.9072\n",
      "Epoch 149/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.3004 - acc: 0.9006 - val_loss: 0.2700 - val_acc: 0.9027\n",
      "Epoch 150/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2868 - acc: 0.9078 - val_loss: 0.1926 - val_acc: 0.9388\n",
      "Epoch 151/800\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.2396 - acc: 0.9270 - val_loss: 0.2159 - val_acc: 0.9343\n",
      "Epoch 152/800\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.3057 - acc: 0.9060 - val_loss: 0.2783 - val_acc: 0.9080\n",
      "Epoch 153/800\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.3565 - acc: 0.8892 - val_loss: 0.2449 - val_acc: 0.9234\n",
      "Epoch 154/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.3452 - acc: 0.8951 - val_loss: 0.5685 - val_acc: 0.8398\n",
      "Epoch 155/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.6969 - acc: 0.8298 - val_loss: 0.3118 - val_acc: 0.8978\n",
      "Epoch 156/800\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.3809 - acc: 0.8787 - val_loss: 0.2339 - val_acc: 0.9245\n",
      "Epoch 157/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.2693 - acc: 0.9167 - val_loss: 0.1757 - val_acc: 0.9448\n",
      "Epoch 158/800\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2468 - acc: 0.9237 - val_loss: 0.1805 - val_acc: 0.9446\n",
      "Epoch 159/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.2554 - acc: 0.9209 - val_loss: 0.1850 - val_acc: 0.9442\n",
      "Epoch 160/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.2473 - acc: 0.9223 - val_loss: 0.1920 - val_acc: 0.9405\n",
      "Epoch 161/800\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2595 - acc: 0.9195 - val_loss: 0.2167 - val_acc: 0.9323\n",
      "Epoch 162/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.2685 - acc: 0.9177 - val_loss: 0.2456 - val_acc: 0.9264\n",
      "Epoch 163/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.3152 - acc: 0.9066 - val_loss: 0.3053 - val_acc: 0.9078\n",
      "Epoch 164/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.3316 - acc: 0.9005 - val_loss: 0.2000 - val_acc: 0.9383\n",
      "Epoch 165/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.2563 - acc: 0.9208 - val_loss: 0.2069 - val_acc: 0.9310\n",
      "Epoch 166/800\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2924 - acc: 0.9046 - val_loss: 0.2530 - val_acc: 0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.3386 - acc: 0.8929 - val_loss: 0.2825 - val_acc: 0.9080\n",
      "Epoch 168/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.3532 - acc: 0.8922 - val_loss: 0.2904 - val_acc: 0.9002\n",
      "Epoch 169/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.3231 - acc: 0.8972 - val_loss: 0.2509 - val_acc: 0.9189\n",
      "Epoch 170/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2958 - acc: 0.9075 - val_loss: 0.1920 - val_acc: 0.9391\n",
      "Epoch 171/800\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2540 - acc: 0.9197 - val_loss: 0.1886 - val_acc: 0.9419\n",
      "Epoch 172/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.3006 - acc: 0.9076 - val_loss: 0.2790 - val_acc: 0.9115\n",
      "Epoch 173/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.3864 - acc: 0.8807 - val_loss: 0.2050 - val_acc: 0.9346\n",
      "Epoch 174/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.2398 - acc: 0.9250 - val_loss: 0.1756 - val_acc: 0.9461\n",
      "Epoch 175/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2098 - acc: 0.9363 - val_loss: 0.1658 - val_acc: 0.9474\n",
      "Epoch 176/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.2086 - acc: 0.9360 - val_loss: 0.1787 - val_acc: 0.9422\n",
      "Epoch 177/800\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.2503 - acc: 0.9207 - val_loss: 0.2680 - val_acc: 0.9005\n",
      "Epoch 178/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.3444 - acc: 0.8869 - val_loss: 0.3833 - val_acc: 0.8655\n",
      "Epoch 179/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.4319 - acc: 0.8730 - val_loss: 0.2895 - val_acc: 0.9121\n",
      "Epoch 180/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.3729 - acc: 0.8912 - val_loss: 0.2330 - val_acc: 0.9269\n",
      "Epoch 181/800\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.2846 - acc: 0.9146 - val_loss: 0.1761 - val_acc: 0.9460\n",
      "Epoch 182/800\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.2402 - acc: 0.9255 - val_loss: 0.1826 - val_acc: 0.9446\n",
      "Epoch 183/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2598 - acc: 0.9186 - val_loss: 0.1803 - val_acc: 0.9470\n",
      "Epoch 184/800\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2623 - acc: 0.9185 - val_loss: 0.1746 - val_acc: 0.9473\n",
      "Epoch 185/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.2273 - acc: 0.9290 - val_loss: 0.1798 - val_acc: 0.9438\n",
      "Epoch 186/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.2278 - acc: 0.9294 - val_loss: 0.1906 - val_acc: 0.9384\n",
      "Epoch 187/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2467 - acc: 0.9231 - val_loss: 0.1847 - val_acc: 0.9396\n",
      "Epoch 188/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2548 - acc: 0.9192 - val_loss: 0.1863 - val_acc: 0.9427\n",
      "Epoch 189/800\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.2477 - acc: 0.9220 - val_loss: 0.2145 - val_acc: 0.9295\n",
      "Epoch 190/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.3084 - acc: 0.9050 - val_loss: 0.2213 - val_acc: 0.9284\n",
      "Epoch 191/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.2875 - acc: 0.9080 - val_loss: 0.2133 - val_acc: 0.9307\n",
      "Epoch 192/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2878 - acc: 0.9066 - val_loss: 0.2495 - val_acc: 0.9115\n",
      "Epoch 193/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.3148 - acc: 0.8985 - val_loss: 0.3502 - val_acc: 0.8787\n",
      "Epoch 194/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.3400 - acc: 0.8941 - val_loss: 0.2455 - val_acc: 0.9209\n",
      "Epoch 195/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2837 - acc: 0.9131 - val_loss: 0.2808 - val_acc: 0.9086\n",
      "Epoch 196/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.3074 - acc: 0.9060 - val_loss: 0.2765 - val_acc: 0.9144\n",
      "Epoch 197/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2786 - acc: 0.9164 - val_loss: 0.1925 - val_acc: 0.9412\n",
      "Epoch 198/800\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2217 - acc: 0.9332 - val_loss: 0.1689 - val_acc: 0.9480\n",
      "Epoch 199/800\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1994 - acc: 0.9387 - val_loss: 0.1548 - val_acc: 0.9515\n",
      "Epoch 200/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.1966 - acc: 0.9400 - val_loss: 0.1710 - val_acc: 0.9426\n",
      "Epoch 201/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2223 - acc: 0.9303 - val_loss: 0.1914 - val_acc: 0.9368\n",
      "Epoch 202/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2540 - acc: 0.9194 - val_loss: 0.1975 - val_acc: 0.9390\n",
      "Epoch 203/800\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.2955 - acc: 0.9080 - val_loss: 0.2399 - val_acc: 0.9266\n",
      "Epoch 204/800\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.3737 - acc: 0.8869 - val_loss: 0.2901 - val_acc: 0.9107\n",
      "Epoch 205/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.3815 - acc: 0.8866 - val_loss: 0.2754 - val_acc: 0.9103\n",
      "Epoch 206/800\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.3043 - acc: 0.9068 - val_loss: 0.1754 - val_acc: 0.9459\n",
      "Epoch 207/800\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.2080 - acc: 0.9356 - val_loss: 0.1574 - val_acc: 0.9521\n",
      "Epoch 208/800\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.1969 - acc: 0.9388 - val_loss: 0.1580 - val_acc: 0.9518\n",
      "Epoch 209/800\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.1985 - acc: 0.9373 - val_loss: 0.1645 - val_acc: 0.9494\n",
      "Epoch 210/800\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.2064 - acc: 0.9338 - val_loss: 0.1792 - val_acc: 0.9463\n",
      "Epoch 211/800\n",
      "60000/60000 [==============================] - 10s 175us/step - loss: 0.2210 - acc: 0.9295 - val_loss: 0.1702 - val_acc: 0.9480\n",
      "Epoch 212/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.2138 - acc: 0.9341 - val_loss: 0.1651 - val_acc: 0.9486\n",
      "Epoch 213/800\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.2405 - acc: 0.9263 - val_loss: 0.2249 - val_acc: 0.9321\n",
      "Epoch 214/800\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.3466 - acc: 0.8986 - val_loss: 0.3196 - val_acc: 0.8981\n",
      "Epoch 215/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.4807 - acc: 0.8674 - val_loss: 0.5629 - val_acc: 0.8588\n",
      "Epoch 216/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.5893 - acc: 0.8559 - val_loss: 0.5736 - val_acc: 0.8661\n",
      "Epoch 217/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.4798 - acc: 0.8827 - val_loss: 0.1998 - val_acc: 0.9382\n",
      "Epoch 218/800\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.2193 - acc: 0.9347 - val_loss: 0.1422 - val_acc: 0.9569\n",
      "Epoch 219/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.1776 - acc: 0.9459 - val_loss: 0.1356 - val_acc: 0.9594\n",
      "Epoch 220/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.1697 - acc: 0.9485 - val_loss: 0.1346 - val_acc: 0.9595\n",
      "Epoch 221/800\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.1672 - acc: 0.9482 - val_loss: 0.1307 - val_acc: 0.9606\n",
      "Epoch 222/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.1675 - acc: 0.9483 - val_loss: 0.1308 - val_acc: 0.9607\n",
      "Epoch 223/800\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.1672 - acc: 0.9487 - val_loss: 0.1412 - val_acc: 0.9565\n",
      "Epoch 224/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.2074 - acc: 0.9326 - val_loss: 0.2805 - val_acc: 0.8940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.3557 - acc: 0.8882 - val_loss: 0.1952 - val_acc: 0.9378\n",
      "Epoch 226/800\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.2294 - acc: 0.9281 - val_loss: 0.1690 - val_acc: 0.9469\n",
      "Epoch 227/800\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.2095 - acc: 0.9372 - val_loss: 0.1522 - val_acc: 0.9543\n",
      "Epoch 228/800\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.2101 - acc: 0.9366 - val_loss: 0.1784 - val_acc: 0.9473\n",
      "Epoch 229/800\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.2530 - acc: 0.9236 - val_loss: 0.2175 - val_acc: 0.9348\n",
      "Epoch 230/800\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.2882 - acc: 0.9136 - val_loss: 0.2086 - val_acc: 0.9334\n",
      "Epoch 231/800\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.2638 - acc: 0.9169 - val_loss: 0.2001 - val_acc: 0.9346\n",
      "Epoch 232/800\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.2171 - acc: 0.9317 - val_loss: 0.1835 - val_acc: 0.9407\n",
      "Epoch 233/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.2121 - acc: 0.9340 - val_loss: 0.1948 - val_acc: 0.9347\n",
      "Epoch 234/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.2224 - acc: 0.9299 - val_loss: 0.1980 - val_acc: 0.9340\n",
      "Epoch 235/800\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.2246 - acc: 0.9300 - val_loss: 0.1887 - val_acc: 0.9415\n",
      "Epoch 236/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.2200 - acc: 0.9324 - val_loss: 0.1708 - val_acc: 0.9461\n",
      "Epoch 237/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.2099 - acc: 0.9347 - val_loss: 0.1849 - val_acc: 0.9399\n",
      "Epoch 238/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.2412 - acc: 0.9245 - val_loss: 0.2141 - val_acc: 0.9303\n",
      "Epoch 239/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2471 - acc: 0.9241 - val_loss: 0.1670 - val_acc: 0.9459\n",
      "Epoch 240/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.2151 - acc: 0.9330 - val_loss: 0.1780 - val_acc: 0.9393\n",
      "Epoch 241/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.2562 - acc: 0.9171 - val_loss: 0.2973 - val_acc: 0.8983\n",
      "Epoch 242/800\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.3004 - acc: 0.9073 - val_loss: 0.1977 - val_acc: 0.9382\n",
      "Epoch 243/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.2253 - acc: 0.9307 - val_loss: 0.1559 - val_acc: 0.9526\n",
      "Epoch 244/800\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.1785 - acc: 0.9446 - val_loss: 0.1396 - val_acc: 0.9591\n",
      "Epoch 245/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.1747 - acc: 0.9467 - val_loss: 0.1417 - val_acc: 0.9573\n",
      "Epoch 246/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.1846 - acc: 0.9426 - val_loss: 0.1698 - val_acc: 0.9480\n",
      "Epoch 247/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.2662 - acc: 0.9197 - val_loss: 0.2685 - val_acc: 0.9151\n",
      "Epoch 248/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.3855 - acc: 0.8893 - val_loss: 0.2897 - val_acc: 0.9123\n",
      "Epoch 249/800\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.5307 - acc: 0.8589 - val_loss: 0.3125 - val_acc: 0.9135\n",
      "Epoch 250/800\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.3718 - acc: 0.8995 - val_loss: 0.2028 - val_acc: 0.9376\n",
      "Epoch 251/800\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.2353 - acc: 0.9295 - val_loss: 0.1348 - val_acc: 0.9588\n",
      "Epoch 252/800\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.1679 - acc: 0.9498 - val_loss: 0.1268 - val_acc: 0.9622\n",
      "Epoch 253/800\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.1633 - acc: 0.9500 - val_loss: 0.1267 - val_acc: 0.9619\n",
      "Epoch 254/800\n",
      "60000/60000 [==============================] - 11s 187us/step - loss: 0.1614 - acc: 0.9499 - val_loss: 0.1277 - val_acc: 0.9612\n",
      "Epoch 255/800\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.1639 - acc: 0.9489 - val_loss: 0.1325 - val_acc: 0.9590\n",
      "Epoch 256/800\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.1767 - acc: 0.9446 - val_loss: 0.1354 - val_acc: 0.9587\n",
      "Epoch 257/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.1891 - acc: 0.9403 - val_loss: 0.1413 - val_acc: 0.9575\n",
      "Epoch 258/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1885 - acc: 0.9415 - val_loss: 0.1354 - val_acc: 0.9598\n",
      "Epoch 259/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1742 - acc: 0.9449 - val_loss: 0.1630 - val_acc: 0.9496\n",
      "Epoch 260/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.2190 - acc: 0.9339 - val_loss: 0.3449 - val_acc: 0.8940\n",
      "Epoch 261/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.4282 - acc: 0.8794 - val_loss: 0.3185 - val_acc: 0.9050\n",
      "Epoch 262/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.4549 - acc: 0.8784 - val_loss: 0.2755 - val_acc: 0.9193\n",
      "Epoch 263/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.4179 - acc: 0.8901 - val_loss: 0.2060 - val_acc: 0.9399\n",
      "Epoch 264/800\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.2464 - acc: 0.9295 - val_loss: 0.1720 - val_acc: 0.9465\n",
      "Epoch 265/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1830 - acc: 0.9446 - val_loss: 0.1284 - val_acc: 0.9582\n",
      "Epoch 266/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.1552 - acc: 0.9522 - val_loss: 0.1232 - val_acc: 0.9607\n",
      "Epoch 267/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1518 - acc: 0.9528 - val_loss: 0.1229 - val_acc: 0.9618\n",
      "Epoch 268/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1525 - acc: 0.9530 - val_loss: 0.1232 - val_acc: 0.9616\n",
      "Epoch 269/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1488 - acc: 0.9545 - val_loss: 0.1240 - val_acc: 0.9618\n",
      "Epoch 270/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1535 - acc: 0.9518 - val_loss: 0.1402 - val_acc: 0.9560\n",
      "Epoch 271/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.1814 - acc: 0.9419 - val_loss: 0.1866 - val_acc: 0.9382\n",
      "Epoch 272/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.2436 - acc: 0.9203 - val_loss: 0.2140 - val_acc: 0.9241\n",
      "Epoch 273/800\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.2708 - acc: 0.9119 - val_loss: 0.2333 - val_acc: 0.9270\n",
      "Epoch 274/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.3224 - acc: 0.9076 - val_loss: 0.2075 - val_acc: 0.9324\n",
      "Epoch 275/800\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.2653 - acc: 0.9196 - val_loss: 0.2535 - val_acc: 0.9213\n",
      "Epoch 276/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.3005 - acc: 0.9105 - val_loss: 0.3462 - val_acc: 0.9014\n",
      "Epoch 277/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.3089 - acc: 0.9114 - val_loss: 0.1800 - val_acc: 0.9424\n",
      "Epoch 278/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.1900 - acc: 0.9410 - val_loss: 0.1255 - val_acc: 0.9610\n",
      "Epoch 279/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.1469 - acc: 0.9536 - val_loss: 0.1189 - val_acc: 0.9638\n",
      "Epoch 280/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.1434 - acc: 0.9550 - val_loss: 0.1164 - val_acc: 0.9641\n",
      "Epoch 281/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.1416 - acc: 0.9553 - val_loss: 0.1179 - val_acc: 0.9636\n",
      "Epoch 282/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1442 - acc: 0.9546 - val_loss: 0.1310 - val_acc: 0.9590\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 283/800\n",
      "60000/60000 [==============================] - 12s 200us/step - loss: 0.1674 - acc: 0.9461 - val_loss: 0.1863 - val_acc: 0.9407\n",
      "Epoch 284/800\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.2564 - acc: 0.9195 - val_loss: 0.2380 - val_acc: 0.9164\n",
      "Epoch 285/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.2904 - acc: 0.9082 - val_loss: 0.2058 - val_acc: 0.9375\n",
      "Epoch 286/800\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.2969 - acc: 0.9117 - val_loss: 0.2022 - val_acc: 0.9417\n",
      "Epoch 287/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.2499 - acc: 0.9267 - val_loss: 0.1613 - val_acc: 0.9511\n",
      "Epoch 288/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.2385 - acc: 0.9264 - val_loss: 0.1472 - val_acc: 0.9564\n",
      "Epoch 289/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.1787 - acc: 0.9453 - val_loss: 0.1171 - val_acc: 0.9652\n",
      "Epoch 290/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1493 - acc: 0.9536 - val_loss: 0.1205 - val_acc: 0.9620\n",
      "Epoch 291/800\n",
      "60000/60000 [==============================] - 12s 198us/step - loss: 0.1562 - acc: 0.9506 - val_loss: 0.1336 - val_acc: 0.9580\n",
      "Epoch 292/800\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.1817 - acc: 0.9434 - val_loss: 0.1778 - val_acc: 0.9435\n",
      "Epoch 293/800\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.2297 - acc: 0.9274 - val_loss: 0.1677 - val_acc: 0.9461\n",
      "Epoch 294/800\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.2138 - acc: 0.9328 - val_loss: 0.1701 - val_acc: 0.9456\n",
      "Epoch 295/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2555 - acc: 0.9217 - val_loss: 0.2794 - val_acc: 0.9200\n",
      "Epoch 296/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3935 - acc: 0.8934 - val_loss: 0.3670 - val_acc: 0.9089\n",
      "Epoch 297/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.3403 - acc: 0.9132 - val_loss: 0.1665 - val_acc: 0.9450\n",
      "Epoch 298/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.1978 - acc: 0.9381 - val_loss: 0.1665 - val_acc: 0.9425\n",
      "Epoch 299/800\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 0.1884 - acc: 0.9410 - val_loss: 0.1217 - val_acc: 0.9623\n",
      "Epoch 300/800\n",
      "60000/60000 [==============================] - 11s 185us/step - loss: 0.1492 - acc: 0.9529 - val_loss: 0.1132 - val_acc: 0.9650\n",
      "Epoch 301/800\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.1358 - acc: 0.9575 - val_loss: 0.1123 - val_acc: 0.9653\n",
      "Epoch 302/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.1352 - acc: 0.9583 - val_loss: 0.1105 - val_acc: 0.9660\n",
      "Epoch 303/800\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.1336 - acc: 0.9584 - val_loss: 0.1136 - val_acc: 0.9641\n",
      "Epoch 304/800\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 0.1367 - acc: 0.9572 - val_loss: 0.1262 - val_acc: 0.9581\n",
      "Epoch 305/800\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.1661 - acc: 0.9468 - val_loss: 0.2074 - val_acc: 0.9323\n",
      "Epoch 306/800\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.3060 - acc: 0.9073 - val_loss: 0.3626 - val_acc: 0.8988\n",
      "Epoch 307/800\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.4816 - acc: 0.8657 - val_loss: 0.5134 - val_acc: 0.8778\n",
      "Epoch 308/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.4449 - acc: 0.8912 - val_loss: 0.2114 - val_acc: 0.9384\n",
      "Epoch 309/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2017 - acc: 0.9415 - val_loss: 0.1321 - val_acc: 0.9585\n",
      "Epoch 310/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1485 - acc: 0.9552 - val_loss: 0.1145 - val_acc: 0.9652\n",
      "Epoch 311/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.1369 - acc: 0.9578 - val_loss: 0.1147 - val_acc: 0.9642\n",
      "Epoch 312/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1374 - acc: 0.9576 - val_loss: 0.1163 - val_acc: 0.9630\n",
      "Epoch 313/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1498 - acc: 0.9529 - val_loss: 0.1515 - val_acc: 0.9479\n",
      "Epoch 314/800\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.1940 - acc: 0.9369 - val_loss: 0.1841 - val_acc: 0.9336\n",
      "Epoch 315/800\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.2043 - acc: 0.9336 - val_loss: 0.1300 - val_acc: 0.9564\n",
      "Epoch 316/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.1468 - acc: 0.9536 - val_loss: 0.1122 - val_acc: 0.9658\n",
      "Epoch 317/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1385 - acc: 0.9559 - val_loss: 0.1227 - val_acc: 0.9628\n",
      "Epoch 318/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.1698 - acc: 0.9472 - val_loss: 0.1845 - val_acc: 0.9409\n",
      "Epoch 319/800\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.2466 - acc: 0.9258 - val_loss: 0.2032 - val_acc: 0.9375\n",
      "Epoch 320/800\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.2147 - acc: 0.9356 - val_loss: 0.2461 - val_acc: 0.9269\n",
      "Epoch 321/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.2641 - acc: 0.9225 - val_loss: 0.2082 - val_acc: 0.9350\n",
      "Epoch 322/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.2357 - acc: 0.9290 - val_loss: 0.1768 - val_acc: 0.9466\n",
      "Epoch 323/800\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.2099 - acc: 0.9363 - val_loss: 0.1446 - val_acc: 0.9565\n",
      "Epoch 324/800\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1785 - acc: 0.9425 - val_loss: 0.1241 - val_acc: 0.9612\n",
      "Epoch 325/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.1465 - acc: 0.9534 - val_loss: 0.1133 - val_acc: 0.9646\n",
      "Epoch 326/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1440 - acc: 0.9551 - val_loss: 0.1240 - val_acc: 0.9626\n",
      "Epoch 327/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1681 - acc: 0.9484 - val_loss: 0.1448 - val_acc: 0.9559\n",
      "Epoch 328/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1929 - acc: 0.9414 - val_loss: 0.1279 - val_acc: 0.9611\n",
      "Epoch 329/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1686 - acc: 0.9470 - val_loss: 0.1244 - val_acc: 0.9629\n",
      "Epoch 330/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1730 - acc: 0.9453 - val_loss: 0.1539 - val_acc: 0.9542\n",
      "Epoch 331/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.2101 - acc: 0.9348 - val_loss: 0.1873 - val_acc: 0.9402\n",
      "Epoch 332/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2340 - acc: 0.9280 - val_loss: 0.2350 - val_acc: 0.9264\n",
      "Epoch 333/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2443 - acc: 0.9267 - val_loss: 0.1734 - val_acc: 0.9466\n",
      "Epoch 334/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1971 - acc: 0.9409 - val_loss: 0.1533 - val_acc: 0.9554\n",
      "Epoch 335/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1840 - acc: 0.9437 - val_loss: 0.1253 - val_acc: 0.9614\n",
      "Epoch 336/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1485 - acc: 0.9531 - val_loss: 0.1181 - val_acc: 0.9649\n",
      "Epoch 337/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1501 - acc: 0.9531 - val_loss: 0.1657 - val_acc: 0.9426\n",
      "Epoch 338/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2696 - acc: 0.9174 - val_loss: 0.3755 - val_acc: 0.8895\n",
      "Epoch 339/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.3140 - acc: 0.9123 - val_loss: 0.1278 - val_acc: 0.9589\n",
      "Epoch 340/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1426 - acc: 0.9551 - val_loss: 0.1275 - val_acc: 0.9593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 341/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1382 - acc: 0.9566 - val_loss: 0.1323 - val_acc: 0.9580\n",
      "Epoch 342/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1575 - acc: 0.9507 - val_loss: 0.2064 - val_acc: 0.9356\n",
      "Epoch 343/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.2607 - acc: 0.9242 - val_loss: 0.2579 - val_acc: 0.9214\n",
      "Epoch 344/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2373 - acc: 0.9288 - val_loss: 0.1399 - val_acc: 0.9584\n",
      "Epoch 345/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1787 - acc: 0.9446 - val_loss: 0.1569 - val_acc: 0.9516\n",
      "Epoch 346/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1955 - acc: 0.9384 - val_loss: 0.1500 - val_acc: 0.9516\n",
      "Epoch 347/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1653 - acc: 0.9480 - val_loss: 0.1275 - val_acc: 0.9585\n",
      "Epoch 348/800\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.1473 - acc: 0.9545 - val_loss: 0.1221 - val_acc: 0.9604\n",
      "Epoch 349/800\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.1412 - acc: 0.9552 - val_loss: 0.1144 - val_acc: 0.9627\n",
      "Epoch 350/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1359 - acc: 0.9579 - val_loss: 0.1162 - val_acc: 0.9630\n",
      "Epoch 351/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1473 - acc: 0.9533 - val_loss: 0.1411 - val_acc: 0.9550\n",
      "Epoch 352/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1929 - acc: 0.9391 - val_loss: 0.1817 - val_acc: 0.9430\n",
      "Epoch 353/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2209 - acc: 0.9320 - val_loss: 0.2383 - val_acc: 0.9321\n",
      "Epoch 354/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2943 - acc: 0.9192 - val_loss: 0.3216 - val_acc: 0.9109\n",
      "Epoch 355/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.3357 - acc: 0.9079 - val_loss: 0.1961 - val_acc: 0.9416\n",
      "Epoch 356/800\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.2488 - acc: 0.9262 - val_loss: 0.2144 - val_acc: 0.9398\n",
      "Epoch 357/800\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.2141 - acc: 0.9408 - val_loss: 0.1300 - val_acc: 0.9585\n",
      "Epoch 358/800\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.1419 - acc: 0.9569 - val_loss: 0.1128 - val_acc: 0.9640\n",
      "Epoch 359/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1283 - acc: 0.9593 - val_loss: 0.1107 - val_acc: 0.9646\n",
      "Epoch 360/800\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.1304 - acc: 0.9592 - val_loss: 0.1135 - val_acc: 0.9633\n",
      "Epoch 361/800\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1385 - acc: 0.9558 - val_loss: 0.1228 - val_acc: 0.9620\n",
      "Epoch 362/800\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.1516 - acc: 0.9516 - val_loss: 0.1228 - val_acc: 0.9616\n",
      "Epoch 363/800\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.1480 - acc: 0.9531 - val_loss: 0.1208 - val_acc: 0.9624\n",
      "Epoch 364/800\n",
      "60000/60000 [==============================] - 12s 199us/step - loss: 0.1583 - acc: 0.9495 - val_loss: 0.1830 - val_acc: 0.9374\n",
      "Epoch 365/800\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.2713 - acc: 0.9180 - val_loss: 0.2611 - val_acc: 0.9116\n",
      "Epoch 366/800\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.2786 - acc: 0.9145 - val_loss: 0.1945 - val_acc: 0.9435\n",
      "Epoch 367/800\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 0.2694 - acc: 0.9218 - val_loss: 0.3120 - val_acc: 0.9140\n",
      "Epoch 368/800\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.3266 - acc: 0.9107 - val_loss: 0.1502 - val_acc: 0.9559\n",
      "Epoch 369/800\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1807 - acc: 0.9463 - val_loss: 0.1268 - val_acc: 0.9622\n",
      "Epoch 370/800\n",
      "60000/60000 [==============================] - 12s 193us/step - loss: 0.1494 - acc: 0.9536 - val_loss: 0.1032 - val_acc: 0.9679\n",
      "Epoch 371/800\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1269 - acc: 0.9604 - val_loss: 0.1017 - val_acc: 0.9682\n",
      "Epoch 372/800\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.1233 - acc: 0.9608 - val_loss: 0.1009 - val_acc: 0.9686\n",
      "Epoch 373/800\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.1235 - acc: 0.9623 - val_loss: 0.1069 - val_acc: 0.9654\n",
      "Epoch 374/800\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.1305 - acc: 0.9595 - val_loss: 0.1235 - val_acc: 0.9601\n",
      "Epoch 375/800\n",
      "60000/60000 [==============================] - 11s 192us/step - loss: 0.1505 - acc: 0.9527 - val_loss: 0.1672 - val_acc: 0.9441\n",
      "Epoch 376/800\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.1843 - acc: 0.9429 - val_loss: 0.1641 - val_acc: 0.9459\n",
      "Epoch 377/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1699 - acc: 0.9474 - val_loss: 0.1691 - val_acc: 0.9482\n",
      "Epoch 378/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1951 - acc: 0.9413 - val_loss: 0.2357 - val_acc: 0.9337\n",
      "Epoch 379/800\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2291 - acc: 0.9339 - val_loss: 0.1610 - val_acc: 0.9502\n",
      "Epoch 380/800\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2556 - acc: 0.9263 - val_loss: 0.2135 - val_acc: 0.9401\n",
      "Epoch 381/800\n",
      "60000/60000 [==============================] - 9s 155us/step - loss: 0.2824 - acc: 0.9222 - val_loss: 0.1724 - val_acc: 0.9534\n",
      "Epoch 382/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2117 - acc: 0.9378 - val_loss: 0.1502 - val_acc: 0.9537\n",
      "Epoch 383/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1923 - acc: 0.9410 - val_loss: 0.1187 - val_acc: 0.9656\n",
      "Epoch 384/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.1380 - acc: 0.9580 - val_loss: 0.1004 - val_acc: 0.9686\n",
      "Epoch 385/800\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.1157 - acc: 0.9645 - val_loss: 0.0994 - val_acc: 0.9688\n",
      "Epoch 386/800\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.1141 - acc: 0.9635 - val_loss: 0.1040 - val_acc: 0.9675\n",
      "Epoch 387/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1216 - acc: 0.9610 - val_loss: 0.1353 - val_acc: 0.9557\n",
      "Epoch 388/800\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2045 - acc: 0.9370 - val_loss: 0.3254 - val_acc: 0.9126\n",
      "Epoch 389/800\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.3332 - acc: 0.9126 - val_loss: 0.2039 - val_acc: 0.9373\n",
      "Epoch 390/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2276 - acc: 0.9332 - val_loss: 0.1827 - val_acc: 0.9462\n",
      "Epoch 391/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1875 - acc: 0.9464 - val_loss: 0.1272 - val_acc: 0.9604\n",
      "Epoch 392/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1579 - acc: 0.9509 - val_loss: 0.1570 - val_acc: 0.9481\n",
      "Epoch 393/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.2199 - acc: 0.9321 - val_loss: 0.2179 - val_acc: 0.9262\n",
      "Epoch 394/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.2177 - acc: 0.9325 - val_loss: 0.1215 - val_acc: 0.9627\n",
      "Epoch 395/800\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.1336 - acc: 0.9588 - val_loss: 0.1257 - val_acc: 0.9603\n",
      "Epoch 396/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1391 - acc: 0.9563 - val_loss: 0.1389 - val_acc: 0.9560\n",
      "Epoch 397/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1511 - acc: 0.9530 - val_loss: 0.1369 - val_acc: 0.9590\n",
      "Epoch 398/800\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.1394 - acc: 0.9565 - val_loss: 0.1145 - val_acc: 0.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 399/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1286 - acc: 0.9601 - val_loss: 0.1314 - val_acc: 0.9579\n",
      "Epoch 400/800\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1577 - acc: 0.9526 - val_loss: 0.1415 - val_acc: 0.9562\n",
      "Epoch 401/800\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.1989 - acc: 0.9425 - val_loss: 0.1891 - val_acc: 0.9459\n",
      "Epoch 402/800\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.3314 - acc: 0.9153 - val_loss: 0.1493 - val_acc: 0.9579\n",
      "Epoch 403/800\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.2422 - acc: 0.9338 - val_loss: 0.2286 - val_acc: 0.9337\n",
      "Epoch 404/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.2735 - acc: 0.9230 - val_loss: 0.1288 - val_acc: 0.9616\n",
      "Epoch 405/800\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1413 - acc: 0.9577 - val_loss: 0.1053 - val_acc: 0.9695\n",
      "Epoch 406/800\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.1237 - acc: 0.9616 - val_loss: 0.0989 - val_acc: 0.9693\n",
      "Epoch 407/800\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.1180 - acc: 0.9635 - val_loss: 0.0962 - val_acc: 0.9708\n",
      "Epoch 408/800\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.1175 - acc: 0.9633 - val_loss: 0.0976 - val_acc: 0.9699\n",
      "Epoch 409/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1201 - acc: 0.9622 - val_loss: 0.1066 - val_acc: 0.9666\n",
      "Epoch 410/800\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.1537 - acc: 0.9518 - val_loss: 0.1673 - val_acc: 0.9498\n",
      "Epoch 411/800\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.2896 - acc: 0.9167 - val_loss: 0.3213 - val_acc: 0.9061\n",
      "Epoch 412/800\n",
      "60000/60000 [==============================] - 24s 396us/step - loss: 0.3743 - acc: 0.8995 - val_loss: 0.3447 - val_acc: 0.9027\n",
      "Epoch 413/800\n",
      "60000/60000 [==============================] - 24s 392us/step - loss: 0.3483 - acc: 0.9105 - val_loss: 0.2000 - val_acc: 0.9458\n",
      "Epoch 414/800\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.1979 - acc: 0.9442 - val_loss: 0.1515 - val_acc: 0.9567\n",
      "Epoch 415/800\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 0.1609 - acc: 0.9534 - val_loss: 0.1435 - val_acc: 0.9552\n",
      "Epoch 416/800\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.1570 - acc: 0.9517 - val_loss: 0.1512 - val_acc: 0.9516\n",
      "Epoch 417/800\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.1582 - acc: 0.9522 - val_loss: 0.1273 - val_acc: 0.9582\n",
      "Epoch 418/800\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.1551 - acc: 0.9519 - val_loss: 0.1443 - val_acc: 0.9544\n",
      "Epoch 419/800\n",
      "60000/60000 [==============================] - 12s 194us/step - loss: 0.1999 - acc: 0.9417 - val_loss: 0.1764 - val_acc: 0.9487\n",
      "Epoch 420/800\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 0.2304 - acc: 0.9350 - val_loss: 0.1380 - val_acc: 0.9605\n",
      "Epoch 421/800\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.1639 - acc: 0.9525 - val_loss: 0.1295 - val_acc: 0.9605\n",
      "Epoch 422/800\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.1511 - acc: 0.9557 - val_loss: 0.1520 - val_acc: 0.9555\n",
      "Epoch 423/800\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.1584 - acc: 0.9534 - val_loss: 0.1297 - val_acc: 0.9611\n",
      "Epoch 424/800\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.1333 - acc: 0.9597 - val_loss: 0.0999 - val_acc: 0.9681\n",
      "Epoch 425/800\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.1238 - acc: 0.9612 - val_loss: 0.1046 - val_acc: 0.9670\n",
      "Epoch 426/800\n",
      "60000/60000 [==============================] - 11s 175us/step - loss: 0.1399 - acc: 0.9566 - val_loss: 0.1192 - val_acc: 0.9633\n",
      "Epoch 427/800\n",
      "60000/60000 [==============================] - 16s 266us/step - loss: 0.1826 - acc: 0.9459 - val_loss: 0.2513 - val_acc: 0.9316\n",
      "Epoch 428/800\n",
      "60000/60000 [==============================] - 19s 313us/step - loss: 0.3906 - acc: 0.9025 - val_loss: 0.2336 - val_acc: 0.9415\n",
      "Epoch 429/800\n",
      "60000/60000 [==============================] - 19s 318us/step - loss: 0.2737 - acc: 0.9286 - val_loss: 0.2354 - val_acc: 0.9347\n",
      "Epoch 430/800\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.2504 - acc: 0.9307 - val_loss: 0.1707 - val_acc: 0.9480\n",
      "Epoch 431/800\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.1787 - acc: 0.9471 - val_loss: 0.1545 - val_acc: 0.9542\n",
      "Epoch 432/800\n",
      "60000/60000 [==============================] - 25s 417us/step - loss: 0.1662 - acc: 0.9498 - val_loss: 0.1411 - val_acc: 0.9562\n",
      "Epoch 433/800\n",
      "60000/60000 [==============================] - 18s 301us/step - loss: 0.1417 - acc: 0.9571 - val_loss: 0.1168 - val_acc: 0.9625\n",
      "Epoch 434/800\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.1233 - acc: 0.9609 - val_loss: 0.1109 - val_acc: 0.9652\n",
      "Epoch 435/800\n",
      "60000/60000 [==============================] - 11s 189us/step - loss: 0.1383 - acc: 0.9573 - val_loss: 0.1550 - val_acc: 0.9493\n",
      "Epoch 436/800\n",
      "60000/60000 [==============================] - 18s 292us/step - loss: 0.2310 - acc: 0.9350 - val_loss: 0.1855 - val_acc: 0.9432\n",
      "Epoch 437/800\n",
      "60000/60000 [==============================] - 24s 394us/step - loss: 0.2440 - acc: 0.9321 - val_loss: 0.1700 - val_acc: 0.9520\n",
      "Epoch 438/800\n",
      "60000/60000 [==============================] - 10s 158us/step - loss: 0.2393 - acc: 0.9343 - val_loss: 0.3617 - val_acc: 0.9136\n",
      "Epoch 439/800\n",
      "60000/60000 [==============================] - 18s 306us/step - loss: 0.3194 - acc: 0.9186 - val_loss: 0.2879 - val_acc: 0.9220\n",
      "Epoch 440/800\n",
      "60000/60000 [==============================] - 18s 300us/step - loss: 0.3447 - acc: 0.9109 - val_loss: 0.2070 - val_acc: 0.9459\n",
      "Epoch 441/800\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2019 - acc: 0.9462 - val_loss: 0.1352 - val_acc: 0.9623\n",
      "Epoch 442/800\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1433 - acc: 0.9583 - val_loss: 0.1090 - val_acc: 0.9661\n",
      "Epoch 443/800\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1214 - acc: 0.9626 - val_loss: 0.0993 - val_acc: 0.9685\n",
      "Epoch 444/800\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1128 - acc: 0.9649 - val_loss: 0.0959 - val_acc: 0.9701\n",
      "Epoch 445/800\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.1087 - acc: 0.9662 - val_loss: 0.0938 - val_acc: 0.9712\n",
      "Epoch 446/800\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.1071 - acc: 0.9671 - val_loss: 0.0936 - val_acc: 0.9719\n",
      "Epoch 447/800\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1178 - acc: 0.9630 - val_loss: 0.1203 - val_acc: 0.9642\n",
      "Epoch 448/800\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.2189 - acc: 0.9381 - val_loss: 0.3750 - val_acc: 0.9017\n",
      "Epoch 449/800\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.5115 - acc: 0.8875 - val_loss: 0.1592 - val_acc: 0.9555\n",
      "Epoch 450/800\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.2423 - acc: 0.9349 - val_loss: 0.1887 - val_acc: 0.9493\n",
      "Epoch 451/800\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.2648 - acc: 0.9327 - val_loss: 0.1410 - val_acc: 0.9605\n",
      "Epoch 452/800\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1677 - acc: 0.9525 - val_loss: 0.2010 - val_acc: 0.9410\n",
      "Epoch 453/800\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.3610 - acc: 0.9168 - val_loss: 0.3419 - val_acc: 0.9077\n",
      "Epoch 454/800\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.3155 - acc: 0.9216 - val_loss: 0.1113 - val_acc: 0.9692\n",
      "Epoch 455/800\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1241 - acc: 0.9635 - val_loss: 0.1011 - val_acc: 0.9697\n",
      "Epoch 456/800\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1189 - acc: 0.9636 - val_loss: 0.0972 - val_acc: 0.9703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/800\n",
      "60000/60000 [==============================] - 9s 152us/step - loss: 0.1100 - acc: 0.9666 - val_loss: 0.0987 - val_acc: 0.9704\n",
      "Epoch 458/800\n",
      "60000/60000 [==============================] - 9s 153us/step - loss: 0.1216 - acc: 0.9623 - val_loss: 0.1328 - val_acc: 0.9602\n",
      "Epoch 459/800\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.1742 - acc: 0.9496 - val_loss: 0.2602 - val_acc: 0.9314\n",
      "Epoch 460/800\n",
      "60000/60000 [==============================] - 20s 329us/step - loss: 0.2756 - acc: 0.9283 - val_loss: 0.2204 - val_acc: 0.9453\n",
      "Epoch 461/800\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.2168 - acc: 0.9431 - val_loss: 0.1881 - val_acc: 0.9489\n",
      "Epoch 462/800\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 0.2651 - acc: 0.9315 - val_loss: 0.2469 - val_acc: 0.9361\n",
      "Epoch 463/800\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.3131 - acc: 0.9266 - val_loss: 0.1443 - val_acc: 0.9606\n",
      "Epoch 464/800\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.2019 - acc: 0.9474 - val_loss: 0.1627 - val_acc: 0.9542\n",
      "Epoch 465/800\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.2316 - acc: 0.9398 - val_loss: 0.3418 - val_acc: 0.9148\n",
      "Epoch 466/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.5157 - acc: 0.8960 - val_loss: 0.2165 - val_acc: 0.9462\n",
      "Epoch 467/800\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.2365 - acc: 0.9406 - val_loss: 0.2122 - val_acc: 0.9423\n",
      "Epoch 468/800\n",
      "60000/60000 [==============================] - 10s 161us/step - loss: 0.3169 - acc: 0.9238 - val_loss: 0.4319 - val_acc: 0.9091\n",
      "Epoch 469/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.4163 - acc: 0.9115 - val_loss: 0.1749 - val_acc: 0.9558\n",
      "Epoch 470/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1777 - acc: 0.9542 - val_loss: 0.1067 - val_acc: 0.9707\n",
      "Epoch 471/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1280 - acc: 0.9643 - val_loss: 0.1000 - val_acc: 0.9704\n",
      "Epoch 472/800\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.1205 - acc: 0.9656 - val_loss: 0.0971 - val_acc: 0.9709\n",
      "Epoch 473/800\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.1226 - acc: 0.9638 - val_loss: 0.1048 - val_acc: 0.9690\n",
      "Epoch 474/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1454 - acc: 0.9578 - val_loss: 0.1428 - val_acc: 0.9572\n",
      "Epoch 475/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2487 - acc: 0.9327 - val_loss: 0.3130 - val_acc: 0.9169\n",
      "Epoch 476/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.4844 - acc: 0.8968 - val_loss: 0.2706 - val_acc: 0.9353\n",
      "Epoch 477/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.4354 - acc: 0.9044 - val_loss: 0.5650 - val_acc: 0.8788\n",
      "Epoch 478/800\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.6987 - acc: 0.8656 - val_loss: 0.4283 - val_acc: 0.9224\n",
      "Epoch 479/800\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.4424 - acc: 0.9142 - val_loss: 0.1709 - val_acc: 0.9636\n",
      "Epoch 480/800\n",
      "60000/60000 [==============================] - 11s 191us/step - loss: 0.1826 - acc: 0.9563 - val_loss: 0.1366 - val_acc: 0.9661\n",
      "Epoch 481/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.1502 - acc: 0.9617 - val_loss: 0.1261 - val_acc: 0.9669\n",
      "Epoch 482/800\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1413 - acc: 0.9622 - val_loss: 0.1201 - val_acc: 0.9675\n",
      "Epoch 483/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.1336 - acc: 0.9622 - val_loss: 0.1209 - val_acc: 0.9655\n",
      "Epoch 484/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1378 - acc: 0.9613 - val_loss: 0.1389 - val_acc: 0.9597\n",
      "Epoch 485/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.1883 - acc: 0.9481 - val_loss: 0.3488 - val_acc: 0.9189\n",
      "Epoch 486/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.4379 - acc: 0.9077 - val_loss: 0.4308 - val_acc: 0.9127\n",
      "Epoch 487/800\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.3344 - acc: 0.9302 - val_loss: 0.1415 - val_acc: 0.9622\n",
      "Epoch 488/800\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1666 - acc: 0.9563 - val_loss: 0.1544 - val_acc: 0.9580\n",
      "Epoch 489/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.2337 - acc: 0.9422 - val_loss: 0.4960 - val_acc: 0.8879\n",
      "Epoch 490/800\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.7091 - acc: 0.8785 - val_loss: 0.2555 - val_acc: 0.9474\n",
      "Epoch 491/800\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.3009 - acc: 0.9372 - val_loss: 0.3562 - val_acc: 0.9319\n",
      "Epoch 492/800\n",
      "60000/60000 [==============================] - 22s 374us/step - loss: 0.4638 - acc: 0.9134 - val_loss: 0.3491 - val_acc: 0.9341\n",
      "Epoch 493/800\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.3615 - acc: 0.9288 - val_loss: 0.1680 - val_acc: 0.9632\n",
      "Epoch 494/800\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.1954 - acc: 0.9550 - val_loss: 0.1205 - val_acc: 0.9705\n",
      "Epoch 495/800\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.1441 - acc: 0.9633 - val_loss: 0.1121 - val_acc: 0.9708\n",
      "Epoch 496/800\n",
      "60000/60000 [==============================] - 22s 369us/step - loss: 0.1295 - acc: 0.9659 - val_loss: 0.1122 - val_acc: 0.9713\n",
      "Epoch 497/800\n",
      "60000/60000 [==============================] - 24s 393us/step - loss: 0.1475 - acc: 0.9602 - val_loss: 0.1646 - val_acc: 0.9551\n",
      "Epoch 498/800\n",
      "60000/60000 [==============================] - 31s 522us/step - loss: 0.3228 - acc: 0.9237 - val_loss: 0.6122 - val_acc: 0.8842\n",
      "Epoch 499/800\n",
      "60000/60000 [==============================] - 21s 342us/step - loss: 0.6810 - acc: 0.8846 - val_loss: 0.1811 - val_acc: 0.9597\n",
      "Epoch 500/800\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.2757 - acc: 0.9387 - val_loss: 0.2344 - val_acc: 0.9486\n",
      "Epoch 501/800\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 0.4453 - acc: 0.9162 - val_loss: 0.2386 - val_acc: 0.9487\n",
      "Epoch 502/800\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 0.3848 - acc: 0.9232 - val_loss: 0.4279 - val_acc: 0.9141\n",
      "Epoch 503/800\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.6747 - acc: 0.8866 - val_loss: 0.6445 - val_acc: 0.8992\n",
      "Epoch 504/800\n",
      "60000/60000 [==============================] - 12s 197us/step - loss: 0.7528 - acc: 0.8864 - val_loss: 0.2722 - val_acc: 0.9438\n",
      "Epoch 505/800\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.3228 - acc: 0.9340 - val_loss: 0.5178 - val_acc: 0.9132\n",
      "Epoch 506/800\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.4902 - acc: 0.9164 - val_loss: 0.2655 - val_acc: 0.9470\n",
      "Epoch 507/800\n",
      "60000/60000 [==============================] - 23s 390us/step - loss: 0.2417 - acc: 0.9515 - val_loss: 0.1403 - val_acc: 0.9689\n",
      "Epoch 508/800\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.1570 - acc: 0.9637 - val_loss: 0.1374 - val_acc: 0.9679\n",
      "Epoch 509/800\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.1520 - acc: 0.9636 - val_loss: 0.1405 - val_acc: 0.9673\n",
      "Epoch 510/800\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.1585 - acc: 0.9614 - val_loss: 0.1501 - val_acc: 0.9659\n",
      "Epoch 511/800\n",
      "60000/60000 [==============================] - 11s 190us/step - loss: 0.1743 - acc: 0.9577 - val_loss: 0.1821 - val_acc: 0.9585\n",
      "Epoch 512/800\n",
      "60000/60000 [==============================] - 11s 188us/step - loss: 0.2472 - acc: 0.9429 - val_loss: 0.3068 - val_acc: 0.9336\n",
      "Epoch 513/800\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.5051 - acc: 0.9100 - val_loss: 0.4188 - val_acc: 0.9208\n",
      "Epoch 514/800\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.5854 - acc: 0.8972 - val_loss: 0.3663 - val_acc: 0.9326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 515/800\n",
      "60000/60000 [==============================] - 11s 182us/step - loss: 0.6708 - acc: 0.8895 - val_loss: 0.4248 - val_acc: 0.9237\n",
      "Epoch 516/800\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.6862 - acc: 0.8889 - val_loss: 0.8050 - val_acc: 0.8906\n",
      "Epoch 517/800\n",
      "60000/60000 [==============================] - 9s 158us/step - loss: 0.6223 - acc: 0.9100 - val_loss: 0.2130 - val_acc: 0.9618\n",
      "Epoch 518/800\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.2137 - acc: 0.9581 - val_loss: 0.1763 - val_acc: 0.9664\n",
      "Epoch 519/800\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1843 - acc: 0.9616 - val_loss: 0.1768 - val_acc: 0.9650\n",
      "Epoch 520/800\n",
      "30000/60000 [==============>...............] - ETA: 5s - loss: 0.1877 - acc: 0.9597"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b0e232c0736a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     validation_data=(x_test, y_test))\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iss-env-py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "batch_size = 30000\n",
    "num_classes = 10\n",
    "epochs = 800\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 2.5103 - acc: 0.4352 - val_loss: 1.4593 - val_acc: 0.5707\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 1.0707 - acc: 0.6925 - val_loss: 0.7585 - val_acc: 0.7527\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.9453 - acc: 0.7137 - val_loss: 0.5580 - val_acc: 0.7960\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.7997 - acc: 0.7561 - val_loss: 0.8622 - val_acc: 0.7618\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 0.8690 - acc: 0.7453 - val_loss: 0.5969 - val_acc: 0.8260\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 14s 235us/step - loss: 0.8042 - acc: 0.7825 - val_loss: 0.3628 - val_acc: 0.8991\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.5861 - acc: 0.8244 - val_loss: 0.4632 - val_acc: 0.8416\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.8534 - acc: 0.7586 - val_loss: 0.5629 - val_acc: 0.8239\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.6051 - acc: 0.8212 - val_loss: 0.5226 - val_acc: 0.8483\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.5459 - acc: 0.8292 - val_loss: 0.3633 - val_acc: 0.8963\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.6627 - acc: 0.8128 - val_loss: 0.5857 - val_acc: 0.8314\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.6119 - acc: 0.8185 - val_loss: 0.4093 - val_acc: 0.8553\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.4637 - acc: 0.8586 - val_loss: 0.3424 - val_acc: 0.8955\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.6573 - acc: 0.8078 - val_loss: 0.4610 - val_acc: 0.8561\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.4392 - acc: 0.8654 - val_loss: 0.3808 - val_acc: 0.8750\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.4249 - acc: 0.8681 - val_loss: 0.3293 - val_acc: 0.9004\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 10s 163us/step - loss: 0.5342 - acc: 0.8338 - val_loss: 0.4324 - val_acc: 0.8675\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.4636 - acc: 0.8572 - val_loss: 0.2684 - val_acc: 0.9231\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.4237 - acc: 0.8714 - val_loss: 0.3158 - val_acc: 0.9044\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.4486 - acc: 0.8623 - val_loss: 0.3181 - val_acc: 0.8943\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.3701 - acc: 0.8851 - val_loss: 0.2530 - val_acc: 0.9230\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.4023 - acc: 0.8751 - val_loss: 0.7363 - val_acc: 0.8135\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.5336 - acc: 0.8514 - val_loss: 0.2138 - val_acc: 0.9346\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 10s 165us/step - loss: 0.2991 - acc: 0.9060 - val_loss: 0.2389 - val_acc: 0.9268\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.3476 - acc: 0.8933 - val_loss: 0.3164 - val_acc: 0.8986\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.4517 - acc: 0.8697 - val_loss: 0.2453 - val_acc: 0.9191\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2953 - acc: 0.9073 - val_loss: 0.2793 - val_acc: 0.9045\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.5353 - acc: 0.8554 - val_loss: 0.2127 - val_acc: 0.9318\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2538 - acc: 0.9231 - val_loss: 0.2135 - val_acc: 0.9307\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 11s 181us/step - loss: 0.3188 - acc: 0.9018 - val_loss: 0.2886 - val_acc: 0.8933\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.4919 - acc: 0.8585 - val_loss: 0.2605 - val_acc: 0.9204\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.2480 - acc: 0.9249 - val_loss: 0.1984 - val_acc: 0.9369\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.2912 - acc: 0.9091 - val_loss: 0.3487 - val_acc: 0.8895\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.4046 - acc: 0.8804 - val_loss: 0.3305 - val_acc: 0.8961\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 14s 229us/step - loss: 0.2570 - acc: 0.9210 - val_loss: 0.1972 - val_acc: 0.9360\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.3347 - acc: 0.9007 - val_loss: 0.4117 - val_acc: 0.8819\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 11s 184us/step - loss: 0.2990 - acc: 0.9083 - val_loss: 0.1757 - val_acc: 0.9429\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.2607 - acc: 0.9197 - val_loss: 0.2050 - val_acc: 0.9341\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 14s 237us/step - loss: 0.3772 - acc: 0.8914 - val_loss: 0.2156 - val_acc: 0.9332\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.2566 - acc: 0.9220 - val_loss: 0.2171 - val_acc: 0.9270\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.2509 - acc: 0.9207 - val_loss: 0.3219 - val_acc: 0.8770\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 18s 302us/step - loss: 0.3123 - acc: 0.9084 - val_loss: 0.1707 - val_acc: 0.9464\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 14s 241us/step - loss: 0.2386 - acc: 0.9260 - val_loss: 0.2122 - val_acc: 0.9295\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.3657 - acc: 0.8925 - val_loss: 0.3455 - val_acc: 0.9019\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.2383 - acc: 0.9273 - val_loss: 0.1611 - val_acc: 0.9493\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 11s 180us/step - loss: 0.2187 - acc: 0.9325 - val_loss: 0.3318 - val_acc: 0.8953\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 10s 173us/step - loss: 0.3357 - acc: 0.9010 - val_loss: 0.1592 - val_acc: 0.9511\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.1926 - acc: 0.9401 - val_loss: 0.3070 - val_acc: 0.8885\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 11s 179us/step - loss: 0.2915 - acc: 0.9117 - val_loss: 0.3311 - val_acc: 0.8966\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 10s 164us/step - loss: 0.2351 - acc: 0.9290 - val_loss: 0.1324 - val_acc: 0.9606\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 10s 169us/step - loss: 0.2305 - acc: 0.9295 - val_loss: 0.2896 - val_acc: 0.9144\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3481 - acc: 0.9056 - val_loss: 0.1624 - val_acc: 0.9491\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.1838 - acc: 0.9433 - val_loss: 0.2447 - val_acc: 0.9250\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 10s 174us/step - loss: 0.2354 - acc: 0.9286 - val_loss: 0.1824 - val_acc: 0.9402\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 11s 176us/step - loss: 0.2797 - acc: 0.9130 - val_loss: 0.2308 - val_acc: 0.9328\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 11s 186us/step - loss: 0.1929 - acc: 0.9410 - val_loss: 0.1677 - val_acc: 0.9453\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.2637 - acc: 0.9216 - val_loss: 0.2684 - val_acc: 0.9211\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.2237 - acc: 0.9313 - val_loss: 0.1508 - val_acc: 0.9512\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.2254 - acc: 0.9325 - val_loss: 0.2962 - val_acc: 0.9154\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.3014 - acc: 0.9194 - val_loss: 0.1194 - val_acc: 0.9642\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.1724 - acc: 0.9473 - val_loss: 0.2052 - val_acc: 0.9317\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.2918 - acc: 0.9160 - val_loss: 0.1330 - val_acc: 0.9575\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.1614 - acc: 0.9503 - val_loss: 0.2155 - val_acc: 0.9333\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2569 - acc: 0.9230 - val_loss: 0.1847 - val_acc: 0.9391\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.1863 - acc: 0.9415 - val_loss: 0.1226 - val_acc: 0.9617\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 9s 151us/step - loss: 0.2438 - acc: 0.9291 - val_loss: 0.2384 - val_acc: 0.9273\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 9s 157us/step - loss: 0.2039 - acc: 0.9401 - val_loss: 0.1125 - val_acc: 0.9663\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 10s 159us/step - loss: 0.2127 - acc: 0.9362 - val_loss: 0.1625 - val_acc: 0.9512\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.2226 - acc: 0.9327 - val_loss: 0.1494 - val_acc: 0.9558\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.1861 - acc: 0.9431 - val_loss: 0.1303 - val_acc: 0.9595\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 9s 154us/step - loss: 0.2505 - acc: 0.9272 - val_loss: 0.1274 - val_acc: 0.9593\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 9s 150us/step - loss: 0.1623 - acc: 0.9494 - val_loss: 0.1250 - val_acc: 0.9606\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 9s 156us/step - loss: 0.3026 - acc: 0.9162 - val_loss: 0.1932 - val_acc: 0.9438\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1656 - acc: 0.9515 - val_loss: 0.1195 - val_acc: 0.9631\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 10s 160us/step - loss: 0.1737 - acc: 0.9474 - val_loss: 0.3701 - val_acc: 0.9052\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 10s 171us/step - loss: 0.2793 - acc: 0.9232 - val_loss: 0.1179 - val_acc: 0.9633\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 12s 195us/step - loss: 0.1526 - acc: 0.9534 - val_loss: 0.1417 - val_acc: 0.9566\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.2444 - acc: 0.9299 - val_loss: 0.1246 - val_acc: 0.9614\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 11s 183us/step - loss: 0.1791 - acc: 0.9457 - val_loss: 0.1909 - val_acc: 0.9465\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 11s 177us/step - loss: 0.2247 - acc: 0.9375 - val_loss: 0.1147 - val_acc: 0.9658\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2118 - acc: 0.9377 - val_loss: 0.5717 - val_acc: 0.8703\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.2337 - acc: 0.9356 - val_loss: 0.1160 - val_acc: 0.9643\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.1809 - acc: 0.9457 - val_loss: 0.1279 - val_acc: 0.9618\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2327 - acc: 0.9347 - val_loss: 0.2323 - val_acc: 0.9369\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2558 - acc: 0.9310 - val_loss: 0.1652 - val_acc: 0.9537\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 10s 172us/step - loss: 0.1650 - acc: 0.9522 - val_loss: 0.1326 - val_acc: 0.9603\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.2176 - acc: 0.9364 - val_loss: 0.3811 - val_acc: 0.9059\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2754 - acc: 0.9286 - val_loss: 0.1464 - val_acc: 0.9557\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.1510 - acc: 0.9548 - val_loss: 0.1271 - val_acc: 0.9615\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.4877 - acc: 0.9011 - val_loss: 0.1894 - val_acc: 0.9539\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.1593 - acc: 0.9569 - val_loss: 0.1184 - val_acc: 0.9654\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2223 - acc: 0.9404 - val_loss: 0.1626 - val_acc: 0.9563\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.3622 - acc: 0.9171 - val_loss: 0.2216 - val_acc: 0.9443\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.2353 - acc: 0.9415 - val_loss: 0.3588 - val_acc: 0.9161\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 10s 168us/step - loss: 0.2348 - acc: 0.9425 - val_loss: 0.1608 - val_acc: 0.9515\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 10s 167us/step - loss: 0.4244 - acc: 0.9085 - val_loss: 0.1879 - val_acc: 0.9572\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2910 - acc: 0.9348 - val_loss: 0.2148 - val_acc: 0.9508\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.3106 - acc: 0.9295 - val_loss: 0.6779 - val_acc: 0.8782\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.4616 - acc: 0.9151 - val_loss: 0.1334 - val_acc: 0.9705\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 10s 166us/step - loss: 0.2333 - acc: 0.9460 - val_loss: 0.3844 - val_acc: 0.9255\n",
      "Test loss: 0.384407030706\n",
      "Test accuracy: 0.9255\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Theano tends to smaller batch size; while Tensorflow larger:\n",
    "#batch_size = 128\n",
    "#batch_size = 30000 # too large\n",
    "batch_size = 6000\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 1.1983 - acc: 0.6819 - val_loss: 0.7099 - val_acc: 0.7895\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.7050 - acc: 0.7976 - val_loss: 0.5626 - val_acc: 0.8335\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 0.5574 - acc: 0.8337 - val_loss: 0.4971 - val_acc: 0.8464\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.4799 - acc: 0.8571 - val_loss: 0.2978 - val_acc: 0.9032\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 0.4297 - acc: 0.8726 - val_loss: 0.5173 - val_acc: 0.8548\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.3927 - acc: 0.8827 - val_loss: 0.2866 - val_acc: 0.9076\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 0.3662 - acc: 0.8922 - val_loss: 0.3031 - val_acc: 0.9116\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.3339 - acc: 0.9012 - val_loss: 0.1972 - val_acc: 0.9396\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 0.3261 - acc: 0.9033 - val_loss: 0.3722 - val_acc: 0.8913\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.3114 - acc: 0.9092 - val_loss: 0.2434 - val_acc: 0.9182\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 0.3167 - acc: 0.9104 - val_loss: 0.2058 - val_acc: 0.9372\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.2876 - acc: 0.9170 - val_loss: 0.2604 - val_acc: 0.9205\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.2918 - acc: 0.9162 - val_loss: 0.2214 - val_acc: 0.9358\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 0.2812 - acc: 0.9202 - val_loss: 0.2403 - val_acc: 0.9309\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 12s 202us/step - loss: 0.3353 - acc: 0.9165 - val_loss: 0.2630 - val_acc: 0.9282\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.3678 - acc: 0.9110 - val_loss: 0.1897 - val_acc: 0.9464\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.4406 - acc: 0.9066 - val_loss: 0.5188 - val_acc: 0.8982\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 0.5395 - acc: 0.9049 - val_loss: 0.7136 - val_acc: 0.8882\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 0.7014 - acc: 0.8967 - val_loss: 0.3176 - val_acc: 0.9503\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 0.8637 - acc: 0.8931 - val_loss: 0.4935 - val_acc: 0.9407\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 1.0482 - acc: 0.8870 - val_loss: 1.3491 - val_acc: 0.8798\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 1.2646 - acc: 0.8806 - val_loss: 1.0923 - val_acc: 0.8966\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 1.4156 - acc: 0.8791 - val_loss: 1.0307 - val_acc: 0.9094\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 13s 225us/step - loss: 1.4507 - acc: 0.8813 - val_loss: 0.8521 - val_acc: 0.9296\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 1.5685 - acc: 0.8767 - val_loss: 1.1308 - val_acc: 0.9137\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 1.6071 - acc: 0.8791 - val_loss: 1.4745 - val_acc: 0.8907\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 1.6431 - acc: 0.8785 - val_loss: 1.2959 - val_acc: 0.9046\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 1.7365 - acc: 0.8758 - val_loss: 1.2037 - val_acc: 0.9134\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 1.7365 - acc: 0.8768 - val_loss: 1.5784 - val_acc: 0.8889\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 1.7479 - acc: 0.8785 - val_loss: 1.0516 - val_acc: 0.9268\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 1.8570 - acc: 0.8728 - val_loss: 1.3460 - val_acc: 0.9073\n",
      "Epoch 32/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 1.8154 - acc: 0.8770 - val_loss: 1.2641 - val_acc: 0.9127\n",
      "Epoch 33/100\n",
      "60000/60000 [==============================] - 13s 213us/step - loss: 1.8358 - acc: 0.8767 - val_loss: 1.3579 - val_acc: 0.9094\n",
      "Epoch 34/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 1.8872 - acc: 0.8743 - val_loss: 1.9626 - val_acc: 0.8703\n",
      "Epoch 35/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 1.8919 - acc: 0.8751 - val_loss: 2.3795 - val_acc: 0.8440\n",
      "Epoch 36/100\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 1.9120 - acc: 0.8742 - val_loss: 1.2970 - val_acc: 0.9150\n",
      "Epoch 37/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 1.8307 - acc: 0.8799 - val_loss: 1.9436 - val_acc: 0.8739\n",
      "Epoch 38/100\n",
      "60000/60000 [==============================] - 14s 227us/step - loss: 1.8584 - acc: 0.8791 - val_loss: 1.6671 - val_acc: 0.8913\n",
      "Epoch 39/100\n",
      "60000/60000 [==============================] - 14s 236us/step - loss: 1.9972 - acc: 0.8702 - val_loss: 2.2106 - val_acc: 0.8561\n",
      "Epoch 40/100\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 1.9345 - acc: 0.8746 - val_loss: 1.7419 - val_acc: 0.8876\n",
      "Epoch 41/100\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 1.9496 - acc: 0.8741 - val_loss: 2.6128 - val_acc: 0.8313\n",
      "Epoch 42/100\n",
      "60000/60000 [==============================] - 20s 334us/step - loss: 1.9705 - acc: 0.8730 - val_loss: 1.1595 - val_acc: 0.9244\n",
      "Epoch 43/100\n",
      "60000/60000 [==============================] - 22s 361us/step - loss: 1.9327 - acc: 0.8756 - val_loss: 1.7940 - val_acc: 0.8849\n",
      "Epoch 44/100\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 1.9549 - acc: 0.8747 - val_loss: 1.5323 - val_acc: 0.9019\n",
      "Epoch 45/100\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 2.0146 - acc: 0.8711 - val_loss: 1.6620 - val_acc: 0.8937\n",
      "Epoch 46/100\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 2.0713 - acc: 0.8679 - val_loss: 1.7558 - val_acc: 0.8880\n",
      "Epoch 47/100\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 1.9827 - acc: 0.8738 - val_loss: 1.5505 - val_acc: 0.9019\n",
      "Epoch 48/100\n",
      "60000/60000 [==============================] - 14s 240us/step - loss: 2.1412 - acc: 0.8641 - val_loss: 2.6389 - val_acc: 0.8325\n",
      "Epoch 49/100\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 2.0914 - acc: 0.8671 - val_loss: 1.4916 - val_acc: 0.9052\n",
      "Epoch 50/100\n",
      "60000/60000 [==============================] - 14s 239us/step - loss: 2.0336 - acc: 0.8708 - val_loss: 1.3915 - val_acc: 0.9121\n",
      "Epoch 51/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.0807 - acc: 0.8676 - val_loss: 1.5742 - val_acc: 0.8999\n",
      "Epoch 52/100\n",
      "60000/60000 [==============================] - 13s 208us/step - loss: 1.9588 - acc: 0.8759 - val_loss: 2.1175 - val_acc: 0.8661\n",
      "Epoch 53/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 2.0648 - acc: 0.8694 - val_loss: 1.4165 - val_acc: 0.9101\n",
      "Epoch 54/100\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 2.1232 - acc: 0.8659 - val_loss: 2.0052 - val_acc: 0.8735\n",
      "Epoch 55/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 2.0777 - acc: 0.8688 - val_loss: 1.8510 - val_acc: 0.8835\n",
      "Epoch 56/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.3462 - acc: 0.8523 - val_loss: 1.8061 - val_acc: 0.8864\n",
      "Epoch 57/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.2410 - acc: 0.8587 - val_loss: 1.6277 - val_acc: 0.8973\n",
      "Epoch 58/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 2.2313 - acc: 0.8593 - val_loss: 1.7725 - val_acc: 0.8885\n",
      "Epoch 59/100\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 2.1204 - acc: 0.8664 - val_loss: 2.8374 - val_acc: 0.8225\n",
      "Epoch 60/100\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 2.2976 - acc: 0.8555 - val_loss: 2.5855 - val_acc: 0.8374\n",
      "Epoch 61/100\n",
      "60000/60000 [==============================] - 12s 205us/step - loss: 2.2642 - acc: 0.8575 - val_loss: 1.5622 - val_acc: 0.9017\n",
      "Epoch 62/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 2.2595 - acc: 0.8578 - val_loss: 1.3797 - val_acc: 0.9126\n",
      "Epoch 63/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 2.2389 - acc: 0.8593 - val_loss: 2.0292 - val_acc: 0.8723\n",
      "Epoch 64/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 2.3240 - acc: 0.8541 - val_loss: 2.4967 - val_acc: 0.8439\n",
      "Epoch 65/100\n",
      "60000/60000 [==============================] - 12s 208us/step - loss: 2.5400 - acc: 0.8408 - val_loss: 2.0424 - val_acc: 0.8718\n",
      "Epoch 66/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 2.3002 - acc: 0.8557 - val_loss: 2.1501 - val_acc: 0.8648\n",
      "Epoch 67/100\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 2.3142 - acc: 0.8549 - val_loss: 2.0986 - val_acc: 0.8678\n",
      "Epoch 68/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.3841 - acc: 0.8508 - val_loss: 1.5505 - val_acc: 0.9024\n",
      "Epoch 69/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 2.2201 - acc: 0.8607 - val_loss: 2.1150 - val_acc: 0.8672\n",
      "Epoch 70/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.4487 - acc: 0.8467 - val_loss: 3.5577 - val_acc: 0.7771\n",
      "Epoch 71/100\n",
      "60000/60000 [==============================] - 13s 212us/step - loss: 2.4842 - acc: 0.8446 - val_loss: 2.5075 - val_acc: 0.8428\n",
      "Epoch 72/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.3675 - acc: 0.8517 - val_loss: 1.2957 - val_acc: 0.9190\n",
      "Epoch 73/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.4414 - acc: 0.8473 - val_loss: 1.7956 - val_acc: 0.8876\n",
      "Epoch 74/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.2903 - acc: 0.8566 - val_loss: 3.0321 - val_acc: 0.8110\n",
      "Epoch 75/100\n",
      "60000/60000 [==============================] - 12s 204us/step - loss: 2.4545 - acc: 0.8464 - val_loss: 2.1510 - val_acc: 0.8655\n",
      "Epoch 76/100\n",
      "60000/60000 [==============================] - 12s 201us/step - loss: 2.3778 - acc: 0.8512 - val_loss: 1.7122 - val_acc: 0.8931\n",
      "Epoch 77/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.4927 - acc: 0.8442 - val_loss: 1.7575 - val_acc: 0.8899\n",
      "Epoch 78/100\n",
      "60000/60000 [==============================] - 13s 222us/step - loss: 2.3570 - acc: 0.8526 - val_loss: 3.2388 - val_acc: 0.7984\n",
      "Epoch 79/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 2.3317 - acc: 0.8543 - val_loss: 1.9705 - val_acc: 0.8770\n",
      "Epoch 80/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.5572 - acc: 0.8402 - val_loss: 2.1015 - val_acc: 0.8683\n",
      "Epoch 81/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 2.5155 - acc: 0.8427 - val_loss: 1.4622 - val_acc: 0.9086\n",
      "Epoch 82/100\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 2.3565 - acc: 0.8528 - val_loss: 2.5910 - val_acc: 0.8383\n",
      "Epoch 83/100\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 2.5259 - acc: 0.8422 - val_loss: 1.2941 - val_acc: 0.9189\n",
      "Epoch 84/100\n",
      "60000/60000 [==============================] - 13s 220us/step - loss: 2.5268 - acc: 0.8422 - val_loss: 1.6586 - val_acc: 0.8964\n",
      "Epoch 85/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.3378 - acc: 0.8540 - val_loss: 1.6145 - val_acc: 0.8991\n",
      "Epoch 86/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.4844 - acc: 0.8449 - val_loss: 3.4026 - val_acc: 0.7876\n",
      "Epoch 87/100\n",
      "60000/60000 [==============================] - 12s 207us/step - loss: 2.3859 - acc: 0.8511 - val_loss: 2.2780 - val_acc: 0.8580\n",
      "Epoch 88/100\n",
      "60000/60000 [==============================] - 12s 206us/step - loss: 2.6985 - acc: 0.8317 - val_loss: 1.5609 - val_acc: 0.9023\n",
      "Epoch 89/100\n",
      "60000/60000 [==============================] - 13s 208us/step - loss: 2.4164 - acc: 0.8491 - val_loss: 3.2581 - val_acc: 0.7970\n",
      "Epoch 90/100\n",
      "60000/60000 [==============================] - 13s 211us/step - loss: 2.5671 - acc: 0.8397 - val_loss: 3.4832 - val_acc: 0.7829\n",
      "Epoch 91/100\n",
      "60000/60000 [==============================] - 13s 215us/step - loss: 2.4330 - acc: 0.8481 - val_loss: 1.7449 - val_acc: 0.8910\n",
      "Epoch 92/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.4962 - acc: 0.8442 - val_loss: 2.1070 - val_acc: 0.8684\n",
      "Epoch 93/100\n",
      "60000/60000 [==============================] - 13s 223us/step - loss: 2.7045 - acc: 0.8313 - val_loss: 2.9763 - val_acc: 0.8140\n",
      "Epoch 94/100\n",
      "60000/60000 [==============================] - 14s 226us/step - loss: 2.4413 - acc: 0.8477 - val_loss: 1.3688 - val_acc: 0.9145\n",
      "Epoch 95/100\n",
      "60000/60000 [==============================] - 13s 224us/step - loss: 2.5852 - acc: 0.8386 - val_loss: 1.4483 - val_acc: 0.9097\n",
      "Epoch 96/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.7827 - acc: 0.8266 - val_loss: 2.0646 - val_acc: 0.8712\n",
      "Epoch 97/100\n",
      "60000/60000 [==============================] - 13s 210us/step - loss: 2.5853 - acc: 0.8388 - val_loss: 2.0162 - val_acc: 0.8739\n",
      "Epoch 98/100\n",
      "60000/60000 [==============================] - 13s 216us/step - loss: 2.3367 - acc: 0.8542 - val_loss: 1.7849 - val_acc: 0.8891\n",
      "Epoch 99/100\n",
      "60000/60000 [==============================] - 13s 209us/step - loss: 2.5639 - acc: 0.8403 - val_loss: 2.6092 - val_acc: 0.8369\n",
      "Epoch 100/100\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 2.4563 - acc: 0.8469 - val_loss: 2.3488 - val_acc: 0.8533\n",
      "Test loss: 2.34884084501\n",
      "Test accuracy: 0.8533\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple deep NN on the MNIST dataset.\n",
    "Gets to 98.40% test accuracy after 20 epochs\n",
    "(there is *a lot* of margin for parameter tuning).\n",
    "2 seconds per epoch on a K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "# Theano tends to smaller batch size; while Tensorflow larger:\n",
    "#batch_size = 128\n",
    "batch_size = 1024\n",
    "\n",
    "num_classes = 10\n",
    "epochs = 100\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
